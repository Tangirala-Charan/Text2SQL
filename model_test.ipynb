{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbbebd5-00f1-45ec-ba79-ae5db162bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib.request\n",
    "import ssl\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")\n",
    "import re\n",
    "from sqlalchemy import inspect\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text \n",
    "import dspy\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa0266c9-9362-4130-b683-015216daf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TOKEN=\"TOKEN\"\n",
    "ENDPOINT = 'https://models.inference.ai.azure.com'\n",
    "HF_TOKEN = 'TOKEN'\n",
    "\n",
    "os.environ['HUGGINGFACE_TOKEN']= HF_TOKEN\n",
    "os.environ['GITHUB_TOKEN']= TOKEN\n",
    "os.environ[\"OPENAI_API_KEY\"] = TOKEN\n",
    "os.environ['OPENAI_API_BASE'] = ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45c974ec-271b-41bd-a710-85b455406f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share generation args between models\n",
    "generation_args = {\n",
    "    \"temperature\":0,\n",
    "    \"max_tokens\":500,\n",
    "    \"stop\":\"\\n\\n\",\n",
    "    \"model_type\":\"chat\",\n",
    "    \"n\": 1\n",
    "}\n",
    "# Model specific args\n",
    "model_info = {\n",
    "    \"gpt-4o\": {\"model\": \"openai/gpt-4o\", \"api_base\": ENDPOINT, \"api_key\":TOKEN},\n",
    "    \"gpt-4\": {\"model\": \"openai/gpt-3.5-turbo\", \"api_base\": ENDPOINT, \"api_key\":TOKEN}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27355d47-d5ed-4b84-b2db-42fbc85af547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the models\n",
    "# lm = StarlingLM(**model_info[\"starling\"], **generation_args)\n",
    "lm = dspy.LM(**model_info[\"gpt-4o\"], **generation_args)\n",
    "evaluator_lm = dspy.LM(**model_info[\"gpt-4o\"], **generation_args)\n",
    "\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8fc7535-c27e-4c49-a6f0-093a3274cb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mdspy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmodel_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'chat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_tokens\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdspy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseCallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnum_retries\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprovider\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfinetuning_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlaunch_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      A language model supporting chat or text completion requests for use with DSPy modules.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Create a new language model instance for use with DSPy modules and programs.\n",
       "\n",
       "Args:\n",
       "    model: The model to use. This should be a string of the form ``\"llm_provider/llm_name\"``\n",
       "           supported by LiteLLM. For example, ``\"openai/gpt-4o\"``.\n",
       "    model_type: The type of the model, either ``\"chat\"`` or ``\"text\"``.\n",
       "    temperature: The sampling temperature to use when generating responses.\n",
       "    max_tokens: The maximum number of tokens to generate per response.\n",
       "    cache: Whether to cache the model responses for reuse to improve performance\n",
       "           and reduce costs.\n",
       "    callbacks: A list of callback functions to run before and after each request.\n",
       "    num_retries: The number of times to retry a request if it fails transiently due to\n",
       "                 network error, rate limiting, etc. Requests are retried with exponential\n",
       "                 backoff.\n",
       "    provider: The provider to use. If not specified, the provider will be inferred from the model.\n",
       "    finetuning_model: The model to finetune. In some providers, the models available for finetuning is different\n",
       "        from the models available for inference.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\legion\\miniconda3\\envs\\myenv\\lib\\site-packages\\dspy\\clients\\lm.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     DummyLM"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dspy.LM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a07e283-0a34-40bf-a014-6055dd8f217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1499, 'Abigayle', 'Mccann', '26-Feb-22', '16-Oct-22', 'Production Technician I', 'Lori Lopez DVM', 'abigayle.mccann@bilearner.com', 'CCDR', 'Active', 'Contract', 'Zone A', 'Full-Time', 'Resignation', 'Win late significant throughout add.', 'Production', 'General - Con', '27/04/1975', 'MA', 'Operator', 'Female', 94816, 'Other', 'Married', 'Fully Meets', 3), (1704, 'Mckenzie', 'Kim', '26-Nov-20', None, 'CIO', 'Rachel Thomas', 'mckenzie.kim@bilearner.com', 'CCDR', 'Active', 'Part-Time', 'Zone C', 'Part-Time', 'Unk', None, 'IT/IS', 'Project Management - Con', '21/06/1994', 'MA', 'Project Manager', 'Female', 59091, 'Hispanic', 'Widowed', 'Fully Meets', 3), (1738, 'Phil', 'Close', '30-May-23', '05-Jul-23', 'Production Technician II', 'Tami Fuentes', 'phil.close@bilearner.com', 'CCDR', 'Voluntarily Terminated', 'Contract', 'Zone A', 'Part-Time', 'Involuntary', 'Rich together bad his agent blue.', 'Production', 'General - Eng', '17/11/1983', 'MA', 'Coordinator', 'Male', 2169, 'White', 'Single', 'Fully Meets', 3), (1883, 'Giselle', 'Butler', '27-Aug-18', '23-Mar-19', 'Production Technician I', 'Regina Goodwin', 'giselle.butler@bilearner.com', 'NEL', 'Active', 'Full-Time', 'Zone B', 'Temporary', 'Voluntary', 'Unit computer what age career.', 'Production', 'Project Management - Con', '03/07/1967', 'MA', 'Project Manager', 'Female', 26876, 'Black', 'Single', 'Fully Meets', 3), (1989, 'Alec', 'Stephens', '25-Feb-20', None, 'Production Technician II', 'Jessica Garcia', 'alec.stephens@bilearner.com', 'PL', 'Active', 'Full-Time', 'Zone A', 'Temporary', 'Unk', None, 'Production', 'Field Operations', '14/06/2000', 'MA', 'Groundman', 'Female', 51952, 'Other', 'Married', 'Fully Meets', 3), (2028, 'Linda', 'Combs', '30-Sep-21', '14-Nov-21', 'Production Technician I', 'Paul Wilcox', 'linda.combs@bilearner.com', 'MSC', 'Voluntarily Terminated', 'Full-Time', 'Zone C', 'Temporary', 'Retirement', 'Half audience option safe.', 'Production', 'Field Operations', '02/05/1981', 'MA', 'Tower Hand', 'Female', 77958, 'Hispanic', 'Widowed', 'Fully Meets', 3), (2059, 'Alfred', 'Manning', '29-Jul-23', '06-Aug-23', 'Production Technician I', 'Sally Owens', 'alfred.manning@bilearner.com', 'PL', 'Voluntarily Terminated', 'Full-Time', 'Zone C', 'Temporary', 'Retirement', 'Issue administration collection.', 'Production', 'General - Con', '27/07/1987', 'MA', 'Laborer', 'Female', 7499, 'White', 'Married', 'Fully Meets', 3), (2348, 'Payten', 'Harvey', '25-Jun-22', None, 'Network Engineer', 'Timothy Waters', 'payten.harvey@bilearner.com', 'EW', 'Active', 'Part-Time', 'Zone C', 'Full-Time', 'Unk', None, 'Production', 'Field Operations', '21/02/1976', 'MA', 'Technician', 'Male', 85605, 'Asian', 'Single', 'Fully Meets', 1), (2351, 'Kendall', 'Mcintyre', '24-Dec-19', '21-Jun-20', 'Data Analyst', 'Rita Abbott', 'kendall.mcintyre@bilearner.com', 'EW', 'Active', 'Contract', 'Zone B', 'Temporary', 'Retirement', 'Market as per stop kid score detail.', 'Production', 'Engineers', '27/02/1943', 'MA', 'Technician', 'Male', 25767, 'Hispanic', 'Widowed', 'Fully Meets', 4), (2436, 'Susan', 'Wiggins', '30-Dec-22', '16-Apr-23', 'Production Manager', 'Anna Garcia', 'susan.wiggins@bilearner.com', 'WBL', 'Terminated for Cause', 'Full-Time', 'Zone B', 'Part-Time', 'Voluntary', 'Result so show improve. Leg message cup else.', 'Production', 'Field Operations', '23/04/1958', 'MA', 'Driller', 'Male', 94765, 'Asian', 'Widowed', 'Fully Meets', 4), (2490, 'Kyle', 'Ali', '27-Sep-21', None, 'Director of Operations', 'Carmen Patterson', 'kyle.ali@bilearner.com', 'MSC', 'Active', 'Contract', 'Zone A', 'Part-Time', 'Unk', None, 'IT/IS', 'General - Con', '21/07/1954', 'MA', 'Laborer', 'Male', 5891, 'Other', 'Widowed', 'Fully Meets', 4), (2503, 'Ally', 'Goodman', '26-Dec-21', '29-Jan-22', 'IT Manager - DB', 'Sean Wong', 'ally.goodman@bilearner.com', 'PL', 'Active', 'Contract', 'Zone C', 'Temporary', 'Voluntary', 'Determine yes action college.', 'IT/IS', 'General - Con', '23/12/1949', 'MA', 'Clerk', 'Male', 6113, 'White', 'Married', 'Fully Meets', 5), (2506, 'Trey', 'Johnston', '30-Jun-22', None, 'Director of Operations', 'Jacob Robinson', 'trey.johnston@bilearner.com', 'SVG', 'Active', 'Full-Time', 'Zone C', 'Full-Time', 'Unk', None, 'IT/IS', 'Field Operations', '12/07/1947', 'MA', 'Groundman', 'Male', 76072, 'White', 'Single', 'Fully Meets', 5), (2578, 'Michelle', 'Carter', '30-May-23', None, 'Area Sales Manager', 'Jon Estes', 'michelle.carter@bilearner.com', 'MSC', 'Active', 'Part-Time', 'Zone A', 'Full-Time', 'Unk', None, 'Sales', 'Shop (Fleet)', '28/01/1996', 'VT', 'Assistant', 'Female', 5664, 'Black', 'Single', 'Fully Meets', 5), (2580, 'Alfred', 'Digitale', '29-Apr-20', '20-Oct-21', 'Area Sales Manager', 'Nathan Kelly', 'alfred.digitale@bilearner.com', 'BPC', 'Active', 'Full-Time', 'Zone A', 'Part-Time', 'Resignation', 'Key whose anyone religious mother movie.', 'Sales', 'Finance & Accounting', '07/04/1954', 'NH', 'Administration', 'Male', 3062, 'White', 'Single', 'Fully Meets', 2), (2840, 'Jordon', 'Wyatt', '26-Apr-23', '19-May-23', 'Production Technician I', 'Yvonne Reilly', 'jordon.wyatt@bilearner.com', 'NEL', 'Active', 'Contract', 'Zone B', 'Part-Time', 'Voluntary', 'From continue left eye.', 'Production', 'Fielders', '29/04/2000', 'MA', 'Engineer', 'Male', 74671, 'Hispanic', 'Divorced', 'Fully Meets', 2), (2882, 'Lamar', 'Kirk', '21-May-19', '05-Jan-20', 'Production Technician I', 'Peter Norton', 'lamar.kirk@bilearner.com', 'PL', 'Voluntarily Terminated', 'Part-Time', 'Zone B', 'Full-Time', 'Retirement', 'Since step style stage sound it.', 'Production', 'Shop (Fleet)', '29/11/1978', 'MA', 'Welder', 'Male', 85827, 'Asian', 'Widowed', 'Fully Meets', 4), (2959, 'Marquis', 'Cardenas', '26-Oct-22', '01-Nov-22', 'Production Technician I', 'Mr. Justin Moore', 'marquis.cardenas@bilearner.com', 'BPC', 'Terminated for Cause', 'Part-Time', 'Zone A', 'Temporary', 'Resignation', 'Account between environmental section group.', 'Production', 'Aerial', '30/08/1942', 'MA', 'Lineman', 'Male', 1015, 'Hispanic', 'Widowed', 'Fully Meets', 2), (3005, 'Mareli', 'Wilson', '29-Dec-20', None, 'Production Technician II', 'Brandon Coleman', 'mareli.wilson@bilearner.com', 'MSC', 'Active', 'Contract', 'Zone C', 'Part-Time', 'Unk', None, 'Production', 'General - Con', '20/01/1943', 'MA', 'Technician', 'Female', 57657, 'Hispanic', 'Widowed', 'Fully Meets', 2), (3100, 'Carsen', 'Schmidt', '25-Oct-20', '28-Dec-21', 'Production Technician I', 'Kevin Davis', 'carsen.schmidt@bilearner.com', 'SVG', 'Active', 'Contract', 'Zone B', 'Temporary', 'Retirement', 'Production senior put.', 'Production', 'General - Con', '08/06/1950', 'MA', 'Laborer', 'Female', 58513, 'White', 'Single', 'Fully Meets', 5), (3234, 'Parker', 'Harrison', '23-Aug-21', None, 'Production Technician I', 'Catherine Harris', 'parker.harrison@bilearner.com', 'SVG', 'Active', 'Part-Time', 'Zone B', 'Temporary', 'Unk', None, 'Production', 'General - Con', '25/04/1959', 'MA', 'Administration', 'Male', 52819, 'Black', 'Widowed', 'Fully Meets', 3), (3237, 'Landon', 'Mayo', '21-Nov-22', None, 'Production Technician II', 'Samantha David', 'landon.mayo@bilearner.com', 'PL', 'Active', 'Contract', 'Zone B', 'Temporary', 'Unk', None, 'Production', 'General - Eng', '08/12/1987', 'MA', 'Drafter', 'Male', 69369, 'White', 'Married', 'Fully Meets', 4), (3276, 'Catherine', 'Anthony', '25-Jan-21', None, 'Production Technician I', 'Joshua Lee', 'catherine.anthony@bilearner.com', 'CCDR', 'Active', 'Contract', 'Zone A', 'Temporary', 'Unk', None, 'Production', 'Engineers', '20/11/1996', 'MA', 'Project Manager', 'Male', 83059, 'Asian', 'Divorced', 'Fully Meets', 2), (3280, 'Makaila', 'Pham', '29-May-23', '23-Jul-23', 'Production Technician II', 'Tamara Bailey', 'makaila.pham@bilearner.com', 'CCDR', 'Voluntarily Terminated', 'Part-Time', 'Zone A', 'Temporary', 'Involuntary', 'Fast light home sign build not.', 'Production', 'Project Management - Con', '09/07/1983', 'MA', 'Manager', 'Male', 59596, 'Other', 'Divorced', 'Fully Meets', 5), (3342, 'London', 'Nunez', '31-Jul-21', None, 'Production Technician II', 'Mrs. Danielle Sanchez', 'london.nunez@bilearner.com', 'NEL', 'Active', 'Full-Time', 'Zone C', 'Part-Time', 'Unk', None, 'Production', 'Aerial', '17/02/2000', 'MA', 'Lineman', 'Male', 35072, 'Other', 'Widowed', 'Fully Meets', 2)]\n"
     ]
    }
   ],
   "source": [
    "# prompt: import a sqlite model from local env\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('employees.db')  # Replace 'your_database.db' with the actual file name\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Example query (replace with your actual queries)\n",
    "cursor.execute(\"SELECT * FROM employee_data WHERE StartDate > '2020-01-01' AND PerformanceScore = 'Fully Meets';\")\n",
    "tables = cursor.fetchall()\n",
    "print(tables)\n",
    "\n",
    "# ... (rest of your code to interact with the database)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1d2ce54-7a71-44ad-8450-72622d21452e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the names of employees working in sales?',\n",
       " 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE BusinessUnit='Sales';\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_set = [\n",
    "    {\n",
    "        \"question\": \"What are the names of employees working in sales?\",\n",
    "        \"gold_query\": \"SELECT FirstName, LastName FROM employee_data WHERE BusinessUnit='Sales';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the email address of the employee with EmpID 200?\",\n",
    "        \"gold_query\": \"SELECT ADEmail FROM employee_data WHERE EmpID=200;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Retrieve the job title of employees under supervisor 'Jane Doe'.\",\n",
    "        \"gold_query\": \"SELECT Title FROM employee_data WHERE Supervisor='Jane Doe';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many employees are currently active?\",\n",
    "        \"gold_query\": \"SELECT COUNT(*) FROM employee_data WHERE EmployeeStatus='Active';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all terminated employees along with their termination reasons.\",\n",
    "        \"gold_query\": \"SELECT FirstName, LastName, TerminationDescription FROM employee_data WHERE TerminationType IS NOT NULL;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the desired salary of applicants for the Software Engineer role?\",\n",
    "        \"gold_query\": \"SELECT DesiredSalary FROM recruitment_data WHERE Title='Software Engineer';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many applicants have more than 5 years of experience?\",\n",
    "        \"gold_query\": \"SELECT COUNT(*) FROM recruitment_data WHERE YearsOfExperience > 5;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the names of all male applicants?\",\n",
    "        \"gold_query\": \"SELECT FirstName, LastName FROM recruitment_data WHERE Gender='Male';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the job titles of applications from California?\",\n",
    "        \"gold_query\": \"SELECT Title FROM recruitment_data WHERE State='CA';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many applicants applied on 15th of Jan, 2024?\",\n",
    "        \"gold_query\": \"SELECT COUNT(*) FROM recruitment_data WHERE ApplicationDate='15-Jan-24';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many training programs were conducted at Brandonview?\",\n",
    "        \"gold_query\": \"SELECT COUNT(*) FROM training_and_development_data WHERE Location='Brandonview';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the training programs with a duration of more than 5 days?\",\n",
    "        \"gold_query\": \"SELECT TrainingProgramName FROM training_and_development_data WHERE TrainingDurationInDays > 5;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What was the total cost of training programs conducted in 2023?\",\n",
    "        \"gold_query\": \"SELECT SUM(TrainingCost) FROM training_and_development_data WHERE TrainingDate LIKE '%23';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the names of trainers who are from an external training program?\",\n",
    "        \"gold_query\": \"SELECT Trainer FROM training_and_development_data WHERE TrainingType='External';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the training outcome of the employee with ID 150?\",\n",
    "        \"gold_query\": \"SELECT TrainingOutcome FROM training_and_development_data WHERE EmpID=150;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the engagement score of employee with ID 101?\",\n",
    "        \"gold_query\": \"SELECT EngagementScore FROM employee_engagement_survey_data WHERE EmpID=101;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many employees scored above 8 in satisfaction?\",\n",
    "        \"gold_query\": \"SELECT COUNT(*) FROM employee_engagement_survey_data WHERE SatisfactionScore > 8;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the work-life balance scores of employees surveyed on the 10th of May, 2024?\",\n",
    "        \"gold_query\": \"SELECT WorkLifeBalanceScore FROM employee_engagement_survey_data WHERE SurveyDate='10/5/2024';\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the average engagement score for all employees?\",\n",
    "        \"gold_query\": \"SELECT AVG(EngagementScore) FROM employee_engagement_survey_data;\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the survey details for employees with engagement scores below 5?\",\n",
    "        \"gold_query\": \"SELECT * FROM employee_engagement_survey_data WHERE EngagementScore < 5;\"\n",
    "    },\n",
    "\t{\n",
    "\t\t\"question\": \"What are the names of employees who are either in the same department as Jane Doe or share the same title?\",\n",
    "\t\t\"gold_query\": \"SELECT FirstName, LastName FROM employee_data WHERE DepartmentType = (SELECT DepartmentType FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe') OR Title = (SELECT Title FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe');\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"What is the number of hires in each year?\",\n",
    "\t\t\"gold_query\": \"SELECT strftime('%Y', '20' || substr(StartDate, 8, 2) || '-' || CASE substr(StartDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2)) AS HireYear, COUNT(*) AS EmployeeCount FROM employee_data WHERE EmployeeStatus = 'Active' AND StartDate IS NOT NULL AND StartDate != '' GROUP BY strftime('%Y', '20' || substr(StartDate, 8, 2) || '-' || CASE substr(StartDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2));\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"Who are the employees who have completed a training program lasting more than 3 days and with a cost above $500?\",\n",
    "\t\t\"gold_query\": \"SELECT e.FirstName, e.LastName, t.TrainingProgramName FROM employee_data e JOIN training_and_development_data t ON e.EmpID = t.EmpID WHERE t.TrainingDurationInDays > 3 AND t.TrainingCost > 500;\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"Who are the employees who have not attended any training program in the last two years?\",\n",
    "\t\t\"gold_query\": \"SELECT FirstName, LastName FROM employee_data WHERE EmpID NOT IN (SELECT EmpID FROM training_and_development_data WHERE TrainingDate > date('now', '-2 years'));\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"Who are the employees with the lowest engagement score in their department?\",\n",
    "\t\t\"gold_query\": \"SELECT FirstName, LastName, DepartmentType, EngagementScore FROM employee_engagement_survey_data ees JOIN employee_data ed ON ees.EmpID = ed.EmpID WHERE EngagementScore = (SELECT MIN(EngagementScore) FROM employee_engagement_survey_data WHERE DepartmentType = ed.DepartmentType);\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"What is the average cost and total number of training programs for each type?\",\n",
    "\t\t\"gold_query\": \"SELECT TrainingType, AVG(TrainingCost) AS AvgCost, COUNT(*) AS ProgramCount FROM training_and_development_data GROUP BY TrainingType;\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"Who are the employees whose last training program was more than a year ago?\",\n",
    "\t\t\"gold_query\": \"SELECT FirstName, LastName FROM employee_data WHERE EmpID IN (SELECT EmpID FROM training_and_development_data GROUP BY EmpID HAVING MAX(TrainingDate < date('now', '-2 year')));\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"Who are the names of employees who attended all training programs conducted in 2023?\",\n",
    "\t\t\"gold_query\": \"SELECT FirstName, LastName FROM employee_data WHERE NOT EXISTS (SELECT 1 FROM training_and_development_data t1 WHERE TrainingDate LIKE '%23' AND t1.TrainingType NOT IN (SELECT TrainingType FROM training_and_development_data t2 WHERE t2.EmpID = employee_data.EmpID));\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"What is the difference between the highest and lowest training costs for each year?\",\n",
    "\t\t\"gold_query\": \"SELECT strftime('%Y', '20' || substr(TrainingDate, 8, 2) || '-' || CASE substr(TrainingDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(TrainingDate, 1, 2)) AS TrainingYear, MAX(TrainingCost) - MIN(TrainingCost) AS CostDifference FROM training_and_development_data GROUP BY strftime('%Y', '20' || substr(TrainingDate, 8, 2) || '-' || CASE substr(TrainingDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(TrainingDate, 1, 2));\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"Who are the employees who have completed the internal training program?\",\n",
    "\t\t\"gold_query\": \"SELECT DISTINCT e.FirstName, e.LastName FROM employee_data e JOIN training_and_development_data t1 ON e.EmpID = t1.EmpID WHERE t1.TrainingType = 'Internal';\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"What is the average satisfaction score for employees by tenure in 5-year increments?\",\n",
    "\t\t\"gold_query\": \"SELECT FLOOR((julianday(DATE('now')) - julianday(CASE WHEN LENGTH(StartDate) = 9 THEN '20' || substr(StartDate, 8, 2) || '-' || CASE substr(StartDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2) ELSE StartDate END)) / 365 / 5) * 5 AS TenureGroup, AVG(SatisfactionScore) AS AvgSatisfaction FROM employee_data ed JOIN employee_engagement_survey_data ees ON ed.EmpID = ees.EmpID WHERE StartDate IS NOT NULL AND SatisfactionScore IS NOT NULL GROUP BY TenureGroup ORDER BY TenureGroup;\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"question\": \"What are the names of employees who have taken training at the same location more than twice?\",\n",
    "\t\t\"gold_query\": \"SELECT FirstName, LastName FROM employee_data e WHERE EmpID IN (SELECT EmpID FROM training_and_development_data GROUP BY EmpID, Location HAVING COUNT(*) > 2);\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "evaluation_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00ad97a-6d35-4dda-b8af-c2a654035d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_schemas = \"\"\"\n",
    "-- Employee Data Table\n",
    "CREATE TABLE employee_data (\n",
    "    EmpID INTEGER,\n",
    "    FirstName TEXT,\n",
    "    LastName TEXT,\n",
    "    StartDate TEXT,\n",
    "    ExitDate TEXT,\n",
    "    Title TEXT,\n",
    "    Supervisor TEXT,\n",
    "    ADEmail TEXT,\n",
    "    BusinessUnit TEXT,\n",
    "    EmployeeStatus TEXT,\n",
    "    EmployeeType TEXT,\n",
    "    PayZone TEXT,\n",
    "    EmployeeClassificationType TEXT,\n",
    "    TerminationType TEXT,\n",
    "    TerminationDescription TEXT,\n",
    "    DepartmentType TEXT,\n",
    "    Division TEXT,\n",
    "    DOB TEXT,\n",
    "    State TEXT,\n",
    "    JobFunctionDescription TEXT,\n",
    "    GenderCode TEXT,\n",
    "    LocationCode INTEGER,\n",
    "    RaceDesc TEXT,\n",
    "    MaritalDesc TEXT,\n",
    "    PerformanceScore TEXT,\n",
    "    CurrentEmployeeRating INTEGER\n",
    ");\n",
    "\n",
    "-- Recruitment Data Table\n",
    "CREATE TABLE recruitment_data (\n",
    "    ApplicantID INTEGER,\n",
    "    ApplicationDate TEXT,\n",
    "    FirstName TEXT,\n",
    "    LastName TEXT,\n",
    "    Gender TEXT,\n",
    "    DOB TEXT,\n",
    "    PhoneNumber TEXT,\n",
    "    Email TEXT,\n",
    "    Address TEXT,\n",
    "    City TEXT,\n",
    "    State TEXT,\n",
    "    ZipCode INTEGER,\n",
    "    Country TEXT,\n",
    "    EducationLevel TEXT,\n",
    "    YearsofExperience INTEGER,\n",
    "    DesiredSalary REAL,\n",
    "    Title TEXT,\n",
    "    Status TEXT\n",
    ");\n",
    "\n",
    "-- Training and Development Data Table\n",
    "CREATE TABLE training_and_development_data (\n",
    "    EmpID INTEGER,\n",
    "    TrainingDate TEXT,\n",
    "    TrainingProgramName TEXT,\n",
    "    TrainingType TEXT,\n",
    "    TrainingOutcome TEXT,\n",
    "    Location TEXT,\n",
    "    Trainer TEXT,\n",
    "    TrainingDurationInDays INTEGER,\n",
    "    TrainingCost INTEGER\n",
    ");\n",
    "\n",
    "-- Employee Engagement Survey Data Table\n",
    "CREATE TABLE employee_engagement_survey_data (\n",
    "    EmpID INTEGER,\n",
    "    SurveyDate TEXT,\n",
    "    EngagementScore INTEGER,\n",
    "    SatisfactionScore INTEGER,\n",
    "    WorklifeBalanceScore INTEGER\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0a51803-73c7-42b4-9258-7615fc3469a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a sanitized column name\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "\n",
    "# Function to create a table from a DataFrame using SQLAlchemy\n",
    "def create_table_from_dataframe(\n",
    "    df: pd.DataFrame, table_name: str, engine, metadata_obj\n",
    "):\n",
    "    # Sanitize column names\n",
    "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
    "    df = df.rename(columns=sanitized_columns)\n",
    "\n",
    "    # Dynamically create columns based on DataFrame columns and data types\n",
    "    columns = [\n",
    "        Column(col, String if dtype == \"object\" else Integer)\n",
    "        for col, dtype in zip(df.columns, df.dtypes)\n",
    "    ]\n",
    "\n",
    "    # Create a table with the defined columns\n",
    "    table = Table(table_name, metadata_obj, *columns)\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata_obj.create_all(engine)\n",
    "\n",
    "    # Insert data from DataFrame into the table\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            insert_stmt = table.insert().values(**row.to_dict())\n",
    "            conn.execute(insert_stmt)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f066525c-694e-40b4-81f0-b8ede8bcaac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir  = \"Processed Data\"\n",
    "def sqlalchemy_engine(region:str):\n",
    "    \"\"\"Create a SQLAlchemy engine for the given region\"\"\"\n",
    "    assert region in os.listdir(processed_dir), f\"{region} is not a valid region from {os.listdir(processed_dir)}\"\n",
    "    # Create a SQLAlchemy database for each region\n",
    "    engine = create_engine(f\"sqlite:///{region}.db\")\n",
    "    metadata_obj = MetaData()\n",
    "    region_path = os.path.join(processed_dir,region)\n",
    "    dfs = []\n",
    "    for dataframes_path in os.listdir(region_path):\n",
    "        if dataframes_path.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(region_path,dataframes_path),index_col=False)\n",
    "            dfs.append((dataframes_path,df))\n",
    "    pbar = tqdm(total=len(dfs),desc=f\"Creating tables for {region}\")\n",
    "    for _, df_table_name in enumerate(dfs):\n",
    "        table_name = df_table_name[0]\n",
    "        table_name = table_name.split(\".\")[0]\n",
    "        df = df_table_name[1]\n",
    "        # print(f\"Creating table: {table_name}\")\n",
    "        create_table_from_dataframe(df,table_name, engine, metadata_obj)\n",
    "        # print(f\"Done creating table for: {table_name}\")\n",
    "        pbar.update(1)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68be1863-e948-4fb3-8c51-b5cd2b9a77ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating tables for India: 100%|███████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# us_engine = sqlalchemy_engine(\"US\")\n",
    "india_engine = sqlalchemy_engine(\"India\")\n",
    "# china_engine = sqlalchemy_engine(\"China\")\n",
    "# europe_engine = sqlalchemy_engine(\"Europe\")\n",
    "# global_engine = sqlalchemy_engine(\"Global\")\n",
    "# aus_nz_canada_engine = sqlalchemy_engine(\"AUS_NZ_CANADA\")\n",
    "# japan_engine = sqlalchemy_engine(\"Japan\")\n",
    "# emerging_engine = sqlalchemy_engine(\"Emerging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97650ee-954c-46ef-95d7-67604568ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_infos(sql_engine:sqlalchemy.engine.base.Engine,region:str):\n",
    "    \"\"\"Get all the tables info in the database based on the given region\"\"\"\n",
    "    inspector = inspect(sql_engine)\n",
    "    table_names = inspector.get_table_names()\n",
    "    table_infos_dict = {tb: [] for tb in table_names}\n",
    "    for tb in table_names:\n",
    "        column_dict = inspector.get_columns(tb)\n",
    "        schema_str = \"\"\n",
    "        primary_keys = []\n",
    "        for col in column_dict:\n",
    "            schema_str += f\"{col['name']} ({col['type']}), \"\n",
    "            if col[\"primary_key\"] not in primary_keys:\n",
    "                primary_keys.append(col[\"name\"])\n",
    "        \n",
    "        with open(os.path.join(processed_dir,region,f\"{tb}.json\")) as f:\n",
    "            table_info = json.loads(f.read())\n",
    "        table_info = list(table_info.items())\n",
    "        # print(table_info)\n",
    "        table_infos_dict[tb] = [\n",
    "            {\n",
    "                \"table_info\": f\"CREATE TABLE {tb} { {schema_str[:-2]}};\",\n",
    "                \"table_summary\": f'{table_info[0][-1]}. {table_info[-1][-1]}. ',\n",
    "            }\n",
    "        ]\n",
    "    return table_infos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4749a1cb-e03a-421b-8c68-42c26c9a43c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DollarIndia': [{'table_info': \"CREATE TABLE DollarIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Average_Company_Age_years_ (INTEGER), Market_Cap_millions_ (INTEGER), Book_Equity_millions_ (INTEGER), Enteprise_Value_millions_ (INTEGER), Invested_Capital_millions_ (INTEGER), Total_Debt_including_leases_millions_ (INTEGER), Revenues_millions_ (INTEGER), Gross_Profit_millions_ (INTEGER), EBITDA_millions_ (INTEGER), EBIT_Operating_Income_millions_ (INTEGER), Net_Income_millions_ (INTEGER)'};\",\n",
       "   'table_summary': 'To report aggregated dollar value of key operating and marker numbers, by industry group, in millions of US $.. This table provides a comprehensive overview of various industries, detailing key financial metrics such as the number of firms, average company age, market capitalization, and profitability indicators. It serves as a valuable resource for understanding the economic landscape and comparing the financial health of different sectors.. '}],\n",
       " 'EVAIndia': [{'table_info': \"CREATE TABLE EVAIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Beta (INTEGER), ROE (INTEGER), Cost_of_Equity (INTEGER), _ROE_COE_ (INTEGER), BV_of_Equity (INTEGER), Equity_EVA (INTEGER), ROC (INTEGER), Cost_of_Capital (INTEGER), _ROC_WACC_ (INTEGER), BV_of_Capital (INTEGER), EVA (INTEGER), E_D_E_ (INTEGER), Std_Dev_in_Stock (INTEGER), Cost_of_Debt (INTEGER), Tax_Rate (INTEGER), After_tax_Cost_of_Debt (INTEGER), D_D_E_ (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate how much firms earn on their investments, relative to what they need to earn to break even, given the risk.. This table summarizes the financial performance metrics of various industries, including key indicators such as the number of firms, beta, return on equity (ROE), cost of equity, equity value added (EVA), and cost of capital. It provides insights into the financial health and risk associated with different sectors, facilitating comparisons and analyses for investors and analysts.. '}],\n",
       " 'EmployeeIndia': [{'table_info': \"CREATE TABLE EmployeeIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Number_of_Employees (INTEGER), Market_Capitalization_millions_ (INTEGER), Revenues_millions_ (INTEGER), Mkt_Cap_per_Employee_ (INTEGER), Revenues_per_Employee_ (INTEGER), Stock_based_Compensation_millions_ (INTEGER), Stock_based_Compensation_as_of_Revenue (INTEGER)'};\",\n",
       "   'table_summary': 'To evaluate how much value and revenue is created by an employee.. This table provides a financial overview of different industries, detailing the number of firms, total employees, market capitalization (in millions), revenues (in millions), and stock-based compensation metrics. It serves as a resource for evaluating the economic impact and performance of various sectors within the market.. '}],\n",
       " 'MktCapIndia': [{'table_info': \"CREATE TABLE MktCapIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Quarter_1 (INTEGER), Quarter_2 (INTEGER), Quarter_3 (INTEGER), Quarter_4 (INTEGER), Quarter_1_1 (INTEGER), Quarter_2_1 (INTEGER), Quarter_3_1 (INTEGER), Quarter_4_1 (INTEGER), 2018_12_31_00_00_00 (INTEGER), 2019_12_31_00_00_00 (INTEGER), 2020_12_31_00_00_00 (INTEGER), 2021_12_31_00_00_00 (INTEGER), 2022_12_31_00_00_00 (INTEGER), 2023_12_31_00_00_00 (INTEGER), 2019 (INTEGER), 2020_0 (INTEGER), 2021_0 (INTEGER), 2022_0 (INTEGER), 2023_0 (INTEGER)'};\",\n",
       "   'table_summary': \"To evaluate how the market's pricing of a sector has changed over time. This table summarizes the financial performance of various industries, detailing the number of firms and their quarterly revenues over several years. It includes key metrics such as total revenue for each quarter and year-end totals, allowing for a comprehensive analysis of industry trends and economic health. The data can be utilized for comparative analysis between industries and for understanding growth patterns over time.. \"}],\n",
       " 'R&DIndia': [{'table_info': \"CREATE TABLE R&DIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), R_D_Capitalized_my_estimate_in_millions_ (INTEGER), Capitalized_R_D_as_of_Invested_Capital (INTEGER), R_D_LTM_in_millions_ (INTEGER), Current_R_D_as_of_Revenue (INTEGER), R_D_1_year_ago_in_millions_ (INTEGER), R_D_2_years_ago_in_millions_ (INTEGER), R_D_3_years_ago_in_millions_ (INTEGER), R_D_4_years_ago (INTEGER), R_D_5_years_ago_in_millions_ (INTEGER), CAGR_in_R_D_Last_5_years (INTEGER)'};\",\n",
       "   'table_summary': 'Measures of accounting returns, to all claim holders (and from operations). This table summarizes the research and development (R&D) investments across various industries. It includes metrics such as the number of firms in each industry, estimated R&D capital, capitalized R&D as a percentage of invested capital, and R&D expenditures over the last five years. The data provides insights into the R&D landscape, highlighting how different sectors allocate resources towards innovation and development.. '}],\n",
       " 'betaIndia': [{'table_info': \"CREATE TABLE betaIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Beta_ (INTEGER), D_E_Ratio (INTEGER), Effective_Tax_rate (INTEGER), Unlevered_beta (INTEGER), Cash_Firm_value (INTEGER), Unlevered_beta_corrected_for_cash (INTEGER), HiLo_Risk (INTEGER), Standard_deviation_of_equity (INTEGER), Standard_deviation_in_operating_income_last_10_years_ (INTEGER), Beta_2020 (INTEGER), Beta_2021 (INTEGER), Beta_2022 (INTEGER), Beta_2023 (INTEGER), Average_Beta_2019_23 (INTEGER)'};\",\n",
       "   'table_summary': 'Industry_Financial_Analysis. This table presents a comprehensive analysis of various industries, detailing key financial metrics such as the number of firms, beta values (which indicate market risk), debt-to-equity ratios, effective tax rates, and cash firm values. The data spans multiple years, providing insights into the financial stability and risk profiles of different sectors, which can be valuable for investors, analysts, and policymakers.. '}],\n",
       " 'capexIndia': [{'table_info': \"CREATE TABLE capexIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Capital_Expenditures_US_millions_ (INTEGER), Depreciation_Amort_US_millions_ (INTEGER), Cap_Ex_Deprecn (INTEGER), Acquisitions_US_millions_ (INTEGER), Net_R_D_US_millions_ (INTEGER), Net_Cap_Ex_Sales (INTEGER), Net_Cap_Ex_EBIT_1_t_ (INTEGER), Sales_Invested_Capital_LTM_ (INTEGER)'};\",\n",
       "   'table_summary': 'To measure how much companies are reinvesting back into their long term assets, as a prelude to forecasting expected growth.. This table presents financial metrics across various industries, detailing the number of firms, capital expenditures, depreciation and amortization costs, acquisitions, net research and development spending, and other key financial ratios. It serves as a comprehensive overview of how different sectors allocate resources and manage investments, providing insights into their operational efficiency and financial performance.. '}],\n",
       " 'dbtfundIndia': [{'table_info': \"CREATE TABLE dbtfundIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Book_Debt_to_Capital (INTEGER), Market_Debt_to_Capital_Unadjusted_ (INTEGER), Market_D_E_unadjusted_ (INTEGER), Market_Debt_to_Capital_adjusted_for_leases_ (INTEGER), Market_D_E_adjusted_for_leases_ (INTEGER), Interest_Coverage_Ratio (INTEGER), Debt_to_EBITDA (INTEGER), Effective_tax_rate (INTEGER), Institutional_Holdings (INTEGER), Std_dev_in_Stock_Prices (INTEGER), EBITDA_EV (INTEGER), Net_PP_E_Total_Assets (INTEGER), Capital_Spending_Total_Assets (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate how much debt companies have used in funding, and some of the fundamentals driving that debt choice. . This table summarizes financial metrics across various industries, including the number of firms, debt-to-capital ratios, interest coverage ratios, and capital spending as a percentage of total assets. It provides insights into the financial stability and operational efficiency of different sectors, making it a valuable resource for investors and analysts.. '}],\n",
       " 'debtdetailsIndia': [{'table_info': \"CREATE TABLE debtdetailsIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Lease_Debt_My_Estimate_ (INTEGER), Conventional_Debt (INTEGER), Total_Debt_with_leases (INTEGER), Interest_expense (INTEGER), Book_interest_rate (INTEGER), Short_term_Debt_as_of_Total_Debt (INTEGER), Lease_Debt_Accounting_ (INTEGER)'};\",\n",
       "   'table_summary': 'Details of debt held by firms (lease vs conventional, ST vs LT). This table summarizes the financial metrics of various industries, detailing the number of firms, estimates of lease and conventional debt, total debt including leases, interest expenses, and relevant interest rates. It provides insights into the debt composition and financial obligations of firms within each industry, facilitating comparisons and assessments of financial stability across sectors.. '}],\n",
       " 'divfcfeIndia': [{'table_info': \"CREATE TABLE divfcfeIndia {'Industry_name (VARCHAR), Number_of_firms (INTEGER), _Dividends_ (INTEGER), _Net_Income_ (INTEGER), Payout (INTEGER), Dividends_Buybacks (INTEGER), Cash_Return_as_of_Net_Income (INTEGER), Dividends_Buybacks_Stock_Issuances (INTEGER), FCFE_before_debt_cash_flows_ (INTEGER), FCFE_after_debt_cash_flows_ (INTEGER), Net_Cash_Returned_FCFE_pre_debt_ (INTEGER), Net_Cash_Returned_FCFE_post_debt_ (INTEGER), Net_Cash_Returned_Net_Income (INTEGER), Cash_Firm_Value (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate how much companies are returning to shareholders, in both dividends and buybacks, relative to potential dividends (FCFE, i.e., cash left over after taxes, reinvestment and net debt cash flows.). This table summarizes the financial performance of various industries, detailing key metrics such as the number of firms, dividends paid, net income, payout ratios, and cash returns. It provides insights into how different sectors manage their earnings and return value to shareholders, highlighting trends in dividend policies and cash flow management across industries.. '}],\n",
       " 'divfundIndia': [{'table_info': \"CREATE TABLE divfundIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Total_Dividends_US_millions_ (INTEGER), Special_Dividends_as_of_Total_Dividends (INTEGER), Dividend_Payout (INTEGER), Dividend_Yield (INTEGER), Market_Cap_US_millions_ (INTEGER), ROE (INTEGER), Institutional_Holdings (INTEGER), Std_Dev_in_Stock_Prices (INTEGER)'};\",\n",
       "   'table_summary': 'Fundamental determinants of dividend policy (and payment). This table summarizes the financial performance of various industries, detailing key metrics such as the number of firms, total dividends in millions, dividend payout ratios, dividend yields, market capitalization, return on equity (ROE), institutional holdings, and the standard deviation of stock prices. It provides insights into the dividend distribution and overall financial health of different sectors, making it a valuable resource for investors and analysts.. '}],\n",
       " 'finflowsIndia': [{'table_info': \"CREATE TABLE finflowsIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Dividends_in_millions (INTEGER), Buybacks_in_millions (INTEGER), Equity_Issuance_in_millions (INTEGER), Net_Equity_Change_in_millions (INTEGER), Net_Equity_Change_as_of_Book_Equity (INTEGER), Debt_Repaid_in_millions (INTEGER), Debt_Raised_in_millions (INTEGER), Net_Debt_Change_in_millions (INTEGER), Net_Change_in_Debt_as_of_Total_Debt (INTEGER), Change_in_Lease_Debt_in_millions (INTEGER)'};\",\n",
       "   'table_summary': \"To estimate the sustainable growth rate in earnings per share for a firm, if margins and ROE are stable. If margins are changing, these fundamental growth rates don't apply.. This table summarizes the financial performance of various industries, detailing metrics such as the number of firms, dividends paid, stock buybacks, equity issuance, net equity changes, and debt management activities. It provides insights into how different sectors manage their capital and financial resources, which can be valuable for investors and analysts.. \"}],\n",
       " 'fundgrEBIndia': [{'table_info': \"CREATE TABLE fundgrEBIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), ROC (INTEGER), Reinvestment_Rate (INTEGER), Expected_Growth_in_EBIT (INTEGER)'};\",\n",
       "   'table_summary': \"To estimate the sustainable growth rate in operating income for a firm, if margins and ROC are stable. If margins are changing, these fundamental growth rates don't apply.. This table summarizes key financial metrics for various industries, including the number of firms, return on capital (ROC), reinvestment rates, and expected growth in EBIT. It provides insights into the economic health and growth prospects of different sectors, making it a valuable resource for investors and analysts.. \"}],\n",
       " 'fundgrIndia': [{'table_info': \"CREATE TABLE fundgrIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), ROE (INTEGER), Retention_Ratio (INTEGER), Fundamental_Growth_ (INTEGER)'};\",\n",
       "   'table_summary': \"To estimate the sustainable growth rate in earnings per share for a firm, if margins and ROE are stable. If margins are changing, these fundamental growth rates don't apply.. This table summarizes key financial metrics across various industries, including the number of firms operating in each sector, their return on equity (ROE), retention ratios, and fundamental growth rates. It provides insights into the financial health and growth prospects of different industries, which can be valuable for investors and analysts.. \"}],\n",
       " 'goodwillIndia': [{'table_info': \"CREATE TABLE goodwillIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Goodwill_in_millions_ (INTEGER), Change_in_Goodwill_in_last_year (INTEGER), Goodwill_as_of_Total_Assets (INTEGER), Impairment_of_Goodwill_in_LTM_in_millioins (INTEGER), Impairment_as_of_Goodwill (INTEGER)'};\",\n",
       "   'table_summary': 'To report historical and expected growth rates in operating metrics. The historical growth rates are compounded, annual values (CAGR).. This table presents an analysis of goodwill across various industries, detailing the number of firms, total goodwill values, changes in goodwill over the past year, and impairment metrics. It serves as a valuable resource for assessing the financial performance and asset valuation of firms within different sectors, highlighting trends and potential risks associated with goodwill impairment.. '}],\n",
       " 'histgrIndia': [{'table_info': \"CREATE TABLE histgrIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), CAGR_in_Net_Income_Last_5_years (INTEGER), CAGR_in_Revenues_Last_5_years (INTEGER), Expected_Growth_in_Revenues_Next_2_years (INTEGER), Expected_Growth_in_Revenues_Next_5_years (INTEGER), Expected_Growth_in_EPS_Next_5_years (INTEGER)'};\",\n",
       "   'table_summary': 'To report historical and expected growth rates in operating metrics. The historical growth rates are compounded, annual values (CAGR).. This table summarizes the financial performance of various industries, detailing the number of firms in each sector, historical growth rates in net income and revenues, and projections for revenue and earnings per share growth over the next two to five years. It serves as a valuable resource for investors and analysts looking to assess industry trends and make informed decisions.. '}],\n",
       " 'insholdIndia': [{'table_info': \"CREATE TABLE insholdIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), CEO_Holding (INTEGER), Corporate_Holdings (INTEGER), Institutional_Holdings (INTEGER), Insider_Holdings (INTEGER)'};\",\n",
       "   'table_summary': 'Look at percent of stock held by insiders and institutions, to get a measure of control and corporate governance.. This table summarizes the ownership distribution across various industries, highlighting the number of firms and the percentage of holdings by CEOs, corporate entities, institutional investors, and insiders. It provides insights into how ownership is structured within different sectors, which can be valuable for investors and analysts looking to understand market dynamics.. '}],\n",
       " 'leaseeffectIndia': [{'table_info': \"CREATE TABLE leaseeffectIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Lease_Expense_Sales (INTEGER), Total_Debt_without_leases (INTEGER), Total_Debt_with_Leases (INTEGER), Lease_Debt_as_of_Total_Debt (INTEGER), Market_Debt_to_Capital_without_leases (INTEGER), Market_Debt_to_Capital_with_leases (INTEGER), Book_Debt_to_Capital_without_leases (INTEGER), Book_Debt_to_Capital_with_leases (INTEGER), Operating_income_before_lease_adj_ (INTEGER), Operating_income_after_lease_adj_ (INTEGER), ROIC_without_leases_ (INTEGER), ROIC_with_leases_ (INTEGER), Pre_tax_Operating_Margin_before_lease_adj_ (INTEGER), Pre_tax_Operating_Margin_after_lease_adj_ (INTEGER), Lease_Debt_My_Estimate_ (INTEGER), Lease_Debt_Accounting_ (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate what effect treating leases as debt has on key operating and financial numbers.. This table summarizes the financial performance of various industries, detailing metrics such as the number of firms, lease expenses, total debt (with and without leases), operating income, and return on invested capital (ROIC) both before and after lease adjustments. It provides insights into the capital structure and operational efficiency of different sectors, aiding in comparative financial analysis.. '}],\n",
       " 'marginIndia': [{'table_info': \"CREATE TABLE marginIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Gross_Margin (INTEGER), Net_Margin (INTEGER), Pre_tax_Pre_stock_compensation_Operating_Margin (INTEGER), Pre_tax_Unadjusted_Operating_Margin (INTEGER), After_tax_Unadjusted_Operating_Margin (INTEGER), Pre_tax_Lease_adjusted_Margin (INTEGER), After_tax_Lease_Adjusted_Margin (INTEGER), Pre_tax_Lease_R_D_adj_Margin (INTEGER), After_tax_Lease_R_D_adj_Margin (INTEGER), EBITDA_Sales (INTEGER), EBITDASG_A_Sales (INTEGER), EBITDAR_D_Sales (INTEGER), COGS_Sales (INTEGER), R_D_Sales (INTEGER), SG_A_Sales (INTEGER), Stock_Based_Compensation_Sales (INTEGER), Lease_Expense_Sales (INTEGER)'};\",\n",
       "   'table_summary': 'Measures of profitability and costs, by industry. This table summarizes the financial performance metrics of various industries, including the number of firms in each sector and key profitability ratios such as gross margin, net margin, and various operating margins. It provides insights into the financial dynamics of industries ranging from Advertising to Beverage sectors, allowing for a comprehensive analysis of their economic viability and operational efficiency.. '}],\n",
       " 'optvarIndia': [{'table_info': \"CREATE TABLE optvarIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Std_Deviation_in_Equity (INTEGER), Std_Deviation_in_Firm_Value (INTEGER), E_D_E_ (INTEGER), D_D_E_ (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate annualized standard deviation in equity and firm values. This table presents financial metrics across various industries, detailing the number of firms, standard deviations in equity and firm value, and additional metrics (E_D_E_ and D_D_E_). It serves as a resource for understanding the financial stability and variability of firms within different sectors, aiding in comparative analysis and investment decisions.. '}],\n",
       " 'pbvIndia': [{'table_info': \"CREATE TABLE pbvIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), PBV (INTEGER), ROE (INTEGER), EV_Invested_Capital (INTEGER), ROIC (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate ratios of market values (equity and firm) to book value (equity and firm), with companion variables (ROE and ROC). This table summarizes key financial metrics across various industries, including the number of firms, price-to-book value (PBV), return on equity (ROE), enterprise value invested capital, and return on invested capital (ROIC). It provides insights into the financial health and valuation of different sectors, facilitating comparisons and analysis for investors and analysts.. '}],\n",
       " 'peIndia': [{'table_info': \"CREATE TABLE peIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), _of_Money_Losing_firms_Trailing_ (INTEGER), Current_PE (INTEGER), Trailing_PE (INTEGER), Forward_PE (INTEGER), Aggregate_Mkt_Cap_Net_Income_all_firms_ (INTEGER), Aggregate_Mkt_Cap_Trailing_Net_Income_only_money_making_firms_ (INTEGER), Expected_growth_next_5_years (INTEGER), PEG_Ratio (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate ratios of market value of equity to equity earnings (PE), in all its different forms.. This table summarizes the financial performance metrics of various industries, detailing the number of firms, the percentage of firms that are losing money, current and trailing price-to-earnings ratios, market capitalization related to net income, and expected growth over the next five years. It provides insights into the economic landscape and helps in comparing the financial viability of different sectors.. '}],\n",
       " 'psIndia': [{'table_info': \"CREATE TABLE psIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Price_Sales (INTEGER), Net_Margin (INTEGER), EV_Sales (INTEGER), Pre_tax_Operating_Margin (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate ratios of market values (equity and firm) to book value (equity and firm), with companion variables (ROE and ROC). This table presents financial metrics for various industries, detailing the number of firms in each sector along with key performance indicators such as Price-to-Sales ratio, Net Margin, Enterprise Value to Sales ratio, and Pre-tax Operating Margin. It serves as a resource for understanding the financial health and valuation of different industries.. '}],\n",
       " 'roeIndia': [{'table_info': \"CREATE TABLE roeIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), ROE_unadjusted_ (INTEGER), ROE_adjusted_for_R_D_ (INTEGER)'};\",\n",
       "   'table_summary': 'To estimate ratios of market values (equity and firm) to book value (equity and firm), with companion variables (ROE and ROC). This table summarizes the financial performance of various industries by presenting the number of firms in each sector along with their unadjusted and R&D-adjusted return on equity (ROE) values. It provides insights into how different industries perform financially and the effect of R&D on their profitability.. '}],\n",
       " 'taxrateIndia': [{'table_info': \"CREATE TABLE taxrateIndia {'Industry_name (VARCHAR), Number_of_firms (INTEGER), Total_Taxable_Income (INTEGER), Total_Taxes_Paid_Accrual_ (INTEGER), Total_Cash_Taxes_Paid (INTEGER), Cash_Taxes_Accrual_Taxes (INTEGER), Average_across_all_companies (INTEGER), Average_across_only_money_making_companies (INTEGER), Aggregate_tax_rate (INTEGER), Average_across_only_money_making_companies_1 (INTEGER), Aggregate_tax_rate_1 (INTEGER)'};\",\n",
       "   'table_summary': \"To estimate how much companies pay in corporate taxes on income. [['Number of firms', 'Number of firms in the indusry grouping.', 'Law of large numbers?'], ['Taxable Income', 'Taxable income, as reported in income statement, aggregated across firms in group, from trailing 12-month income statement', 'Income subject to taxation, allowing for all dedutions allowed by tax law, reported in income statement.'], ['Taxes paid (accrual)', 'Taxes, as reported in income statement, aggregated across firms in group, from trailing 12-month income statement', 'Accrual estimate of taxes payable'], ['Taxes paid (cash)', 'Cash taxes, aggregated across firms in group, from trailing 12-month cash flow statements', 'Cash taxes paid'], ['Cash Taxes/ Accrual Taxes', 'Cash Taxes/ Accrual Taxes, aggregated across firms in group, from trailing 12-month income statement', 'Measures how much companies actually pay in tax, relative to estimated tax.'], ['Effective Tax Rate', 'Accrual Taxes/ Accrual Taxable Income, from trailing 12 months of financials. Estimated in three ways: (1) Average across all firms, including money losing firms (which usually pay no taxes), (2) Average across only firms that have positive taxable income and (3) Aggregated taxes/ aggregated taxable income, across all firms.', 'Accrual Tax rate paid on income. Can be compared to marginal tax rate, and can be the cause of deferred taxes. The simple average across all firms, since it includes money losing companies, will be skewed down.'], ['Cash Tax Rate', 'Cash Taxes/ Accrual Taxable Income,  from trailing 12 months of financials. Estimated in three ways: (1) Average across all firms, including money losing firms (which usually pay no taxes), (2) Average across only firms that have positive taxable income and (3) Aggregated taxes/ aggregated taxable income, across all firms.', 'Cash Tax rate paid on income. The simple average across all firms, since it includes money losing companies, will be skewed down.']]. \"}],\n",
       " 'totalbetaIndia': [{'table_info': \"CREATE TABLE totalbetaIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Average_Unlevered_Beta (INTEGER), Average_Levered_Beta (INTEGER), Average_correlation_with_the_market (INTEGER), Total_Unlevered_Beta (INTEGER), Total_Levered_Beta (INTEGER)'};\",\n",
       "   'table_summary': \"To estimate risk in a company from the perspective of  a completely undiversified investor (with all of his or her money invested just in one company). [['Number of firms', 'Number of firms in the indusry grouping.', 'Law of large numbers?'], ['Average Unlevered Beta', 'Unlevered beta, corrected for cash, of companies in the business. See the beta spreadsheet for details of calculation.', 'Income subject to taxation, allowing for all dedutions allowed by tax law, reported in income statement.'], ['Average Levered Beta', 'Levered beta, corrected for cash, of companies in the busines and using the aggregate debt to equity ratio of companies in the group. See the beta spreadsheet for details.', 'Accrual estimate of taxes payable'], ['Average correlation with the market', 'Correlation of stock with the market index, using two years of weekly returns, averaged across stocks in the group.', 'Cash taxes paid'], ['Total Unlevered Beta', 'Total Unlevered Beta = Unlevered Beta/ Correlation with the market. Expands risk measure to include all risk in the firm, not just the market risk.', 'Expands risk measure (beta), before considering debt, to include company-specific risk that would normally be diversified away, be acuse investor is not diversified.'], ['Total Levered Beta', 'Total Levered Beta = Levered Beta/ Correlation with the market. Expands risk measure to include all risk in the firm, not just the market risk.', 'Expands risk measure (beta), after incorporating risk added by debt, to include company-specific risk that would normally be diversified away, be acuse investor is not diversified.']]. \"}],\n",
       " 'vebitdaIndia': [{'table_info': \"CREATE TABLE vebitdaIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), EV_EBITDAR_D (INTEGER), EV_EBITDA (INTEGER), EV_EBIT (INTEGER), EV_EBIT_1_t_ (INTEGER), EV_EBITDAR_D_1 (INTEGER), EV_EBITDA_1 (INTEGER), EV_EBIT_1 (INTEGER), EV_EBIT_1_t__1 (INTEGER)'};\",\n",
       "   'table_summary': \"To measure the market value of the operating assets of firms, relative to operating fundamentals.. [['Number of firms', 'Number of firms in the indusry grouping.', 'Law of large numbers?'], ['EV/EBITDAR&D', 'Aggregate enterprise value divided by aggregate earnings before interest, taxes, depreciation and R&D, across all firms in group. (Enterprise Value = Market Capitalization + Total Debt - Cash)', 'Multiple of operating cash flows, with R&D treated as a cap exp, that firms trade at.'], ['EV/EBITDA', 'Aggregate enterprise value divided by aggregate earnings before interest, taxes and depreciation, across all firms in group. (Enterprise Value = Market Capitalization + Total Debt - Cash)', 'Multiple of operating cash flows, that firms trade at (treating R&D as an operating expense, the conventional accounting practice).'], ['EV/EBIT', 'Aggregate enterprise value divided by aggregate earnings before interest and taxes, across all firms in group. (Enterprise Value = Market Capitalization + Total Debt - Cash)', 'Multiple of pre-tax operating earnings, that firms trade at.'], ['EV/EBIT (1-t)', 'Aggregate enterprise value divided by aggregate earnings before interest, but after taxes, across all firms in group. (Enterprise Value = Market Capitalization + Total Debt - Cash)', 'Multiple of after-tax operating earnings, that firms trade at.']]. \"}],\n",
       " 'waccIndia': [{'table_info': \"CREATE TABLE waccIndia {'Industry_Name (VARCHAR), Number_of_Firms (INTEGER), Beta (INTEGER), Cost_of_Equity (INTEGER), E_D_E_ (INTEGER), Std_Dev_in_Stock (INTEGER), Cost_of_Debt (INTEGER), Tax_Rate (INTEGER), After_tax_Cost_of_Debt (INTEGER), D_D_E_ (INTEGER), Cost_of_Capital (INTEGER), Cost_of_Capital_Local_Currency_ (INTEGER)'};\",\n",
       "   'table_summary': \"To estimate the hurdle rate (required return) on both equity and overall capital invested for firms.. [['Number of firms', 'Number of firms in the indusry grouping.', 'Law of large numbers?'], ['Beta', 'Average regression beta across companies in the group.', 'Relative risk of sector'], ['Cost of Equity', 'Risk free Rate + Beta * Equity Risk Premium, in US $', 'Required return on equity, given equity risk (beta).'], ['D/(D+E)', 'Total Debt (including lease debt)/ (Total Debt (including lease debt)+ Market Cap), aggregated across all firms in group, with all numbers other than market cap coming from most recent balance sheet; market cap is as of last day of the most recent year.', 'Measure of debt used, as a proportion of overall funding (based upon market value)'], ['Cost of debt', 'Pre-tax cost of borrowing for sector, estimated based upon the standard deviation of equity.', 'This is an approximation, but the alternatives are not attractive. I could estimate the average cost of debt across firms in the group, but many of them are unrated and there are outliers.'], ['After-tax Cost of Debt', 'Pre-tax cost of borrowing  (1- Marginal tax rate), in US $', 'Interest saves you taxes, at the margin.'], ['Cost of Capital', 'Cost of Equity * (Equity/ (Debt + Equity)) + Cost of Debt (1- Marginal tax rate) *(Debt/ (Debt + Equity)), with aggregated debt and market equity values across all companies in the sector, using most recent balance sheet for debt and most recent year-end for equity.', 'Required return on invested capital.'], ['Cost of Capital (local currency)', 'You can convert the $ cost of capital for a sector into any other currency, if you can estimate an expected inflation rate for the local currency.', 'Required return on invested capital, converted into local currency.']]. \"}],\n",
       " 'wcdataIndia': [{'table_info': \"CREATE TABLE wcdataIndia {'Industry_Name (VARCHAR), Number_of_firms (INTEGER), Acc_Rec_Sales (INTEGER), Inventory_Sales (INTEGER), Acc_Pay_Sales (INTEGER), Non_cash_WC_Sales (INTEGER)'};\",\n",
       "   'table_summary': \"To measure how much different working capital components are, as a percent of revenues.. [['Number of firms', 'Number of firms in the indusry grouping.', 'Law of large numbers?'], ['Acc Rec/ Sales', 'Aggregated accounts receivable divided by aggregated sales, across all companies in group.', 'Investment in receivables, a consequence of selling on credit, and a drain on cash.'], ['Inventory/Sales', 'Aggregated inventory divided by aggregated sales, across all companies in group.', 'Investment in inventory, a consequence of carrying goods in inventory, and a drain on cash.'], ['Acc Pay/ Sales', 'Aggregated accounts payable divided by aggregated sales, across all companies in group.', 'Value of payables, a consequence of using credit in operations, and a source of cash flow.'], ['Non-cash WC/ Sales', 'Aggregated non-cash working capital divided by aggregated sales, across all companies in group. (Non-cash working capital = (Current Assets - Cash) - (Current liabilities - ST Interest-bearing Debt))', 'Overall investment in non-cash working capital, and a drain on cash.']]. \"}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "india_tb_dict = get_table_infos(india_engine,\"India\")\n",
    "india_tb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0558f438-c133-4186-af0b-e9e7601573a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'How many employees are currently active?', 'gold_query': \"SELECT COUNT(*) FROM employee_data WHERE EmployeeStatus='Active';\"}, {'question': 'What are the names of all male applicants?', 'gold_query': \"SELECT FirstName, LastName FROM recruitment_data WHERE Gender='Male';\"}, {'question': 'Who are the employees who have completed the internal training program?', 'gold_query': \"SELECT DISTINCT e.FirstName, e.LastName FROM employee_data e JOIN training_and_development_data t1 ON e.EmpID = t1.EmpID WHERE t1.TrainingType = 'Internal';\"}, {'question': 'What are the names of employees who are either in the same department as Jane Doe or share the same title?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE DepartmentType = (SELECT DepartmentType FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe') OR Title = (SELECT Title FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe');\"}, {'question': 'What are the survey details for employees with engagement scores below 5?', 'gold_query': 'SELECT * FROM employee_engagement_survey_data WHERE EngagementScore < 5;'}, {'question': 'What is the desired salary of applicants for the Software Engineer role?', 'gold_query': \"SELECT DesiredSalary FROM recruitment_data WHERE Title='Software Engineer';\"}, {'question': 'What are the names of employees working in sales?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE BusinessUnit='Sales';\"}, {'question': 'How many training programs were conducted at Brandonview?', 'gold_query': \"SELECT COUNT(*) FROM training_and_development_data WHERE Location='Brandonview';\"}, {'question': 'What is the training outcome of the employee with ID 150?', 'gold_query': 'SELECT TrainingOutcome FROM training_and_development_data WHERE EmpID=150;'}, {'question': 'Who are the employees whose last training program was more than a year ago?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE EmpID IN (SELECT EmpID FROM training_and_development_data GROUP BY EmpID HAVING MAX(TrainingDate < date('now', '-2 year')));\"}, {'question': 'What is the work-life balance scores of employees surveyed on the 10th of May, 2024?', 'gold_query': \"SELECT WorkLifeBalanceScore FROM employee_engagement_survey_data WHERE SurveyDate='10/10/2024';\"}, {'question': 'What is the number of hires in each year?', 'gold_query': \"SELECT strftime('%Y', '20' || substr(StartDate, 8, 2) || '-' || CASE substr(StartDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2)) AS HireYear, COUNT(*) AS EmployeeCount FROM employee_data WHERE EmployeeStatus = 'Active' AND StartDate IS NOT NULL AND StartDate != '' GROUP BY strftime('%Y', '20' || substr(StartDate, 8, 2) || '-' || CASE substr(StartDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2));\"}, {'question': 'Who are the names of employees who attended all training programs conducted in 2023?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE NOT EXISTS (SELECT 1 FROM training_and_development_data t1 WHERE TrainingDate LIKE '%23' AND t1.TrainingType NOT IN (SELECT TrainingType FROM training_and_development_data t2 WHERE t2.EmpID = employee_data.EmpID));\"}, {'question': 'Who are the employees who have not attended any training program in the last two years?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE EmpID NOT IN (SELECT EmpID FROM training_and_development_data WHERE TrainingDate > date('now', '-2 years'));\"}, {'question': \"Retrieve the job title of employees under supervisor 'Jane Doe'.\", 'gold_query': \"SELECT Title FROM employee_data WHERE Supervisor='Jane Doe';\"}, {'question': 'Who are the employees who have completed a training program lasting more than 3 days and with a cost above $500?', 'gold_query': 'SELECT e.FirstName, e.LastName, t.TrainingProgramName FROM employee_data e JOIN training_and_development_data t ON e.EmpID = t.EmpID WHERE t.TrainingDurationInDays > 3 AND t.TrainingCost > 500;'}, {'question': 'List all terminated employees along with their termination reasons.', 'gold_query': 'SELECT FirstName, LastName, TerminationDescription FROM employee_data WHERE TerminationType IS NOT NULL;'}, {'question': 'What is the average cost and total number of training programs for each type?', 'gold_query': 'SELECT TrainingType, AVG(TrainingCost) AS AvgCost, COUNT(*) AS ProgramCount FROM training_and_development_data GROUP BY TrainingType;'}, {'question': 'How many applicants have more than 5 years of experience?', 'gold_query': 'SELECT COUNT(*) FROM recruitment_data WHERE YearsOfExperience > 5;'}, {'question': 'What is the average engagement score for all employees?', 'gold_query': 'SELECT AVG(EngagementScore) FROM employee_engagement_survey_data;'}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.Random(0).shuffle(evaluation_set)\n",
    "trainset, devset, testset = evaluation_set[:20], evaluation_set[20:25], evaluation_set[25:32]\n",
    "\n",
    "len(trainset), len(devset), len(testset)\n",
    "\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "373b2a48-cf8b-4a75-bc39-b9dfc7bbc8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlparse\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: sqlparse\n",
      "Successfully installed sqlparse-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2aee49e-b1ec-4b0e-8417-e0592e365fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "import sqlparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_sql_string(sql_string):\n",
    "    sql_query = re.sub(r'```sql\\n|```', '', sql_string).strip()\n",
    "    sql_query = sql_query.strip()\n",
    "    sql_query = re.sub(r'\\s+', ' ', sql_query)\n",
    "    sql_query = re.sub(\n",
    "        r'\\b(select|from|where|count|as|and|or|in|not|is|like|group|order|by|having|limit|join)\\b',\n",
    "        lambda match: match.group(0).upper(),\n",
    "        sql_query,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    sql_query = re.sub(r'\\s*,\\s*', ', ', sql_query)\n",
    "    sql_query = re.sub(r'\\s*\\(\\s*', '(', sql_query)\n",
    "    sql_query = re.sub(r'\\s*\\)\\s*', ')', sql_query)\n",
    "    return sql_query\n",
    "\n",
    "def execute_sql_query(db_connection, sql_query):\n",
    "    \"\"\"Executes the SQL query on the SQLite database and returns the result\"\"\"\n",
    "    try:\n",
    "        cursor = db_connection.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        return None\n",
    "\n",
    "def compare_sqls(ground_truth, prediction, db_connection):\n",
    "    \"\"\"Compare execution results of ground truth and predicted SQL queries.\"\"\"\n",
    "    ground_truth = normalize_sql_string(ground_truth)\n",
    "    prediction = normalize_sql_string(prediction)\n",
    "\n",
    "    # Execute both SQL queries on the database\n",
    "    ground_truth_result = execute_sql_query(db_connection, ground_truth)\n",
    "    prediction_result = execute_sql_query(db_connection, prediction)\n",
    "\n",
    "    print('\\nground truth sql query: ', ground_truth)\n",
    "    print('ground truth result: ', ground_truth_result)\n",
    "    print('prediction sql query: ', prediction)\n",
    "    print('prediction result: ', prediction_result)\n",
    "\n",
    "    # Compare results based on row count and values\n",
    "    if ground_truth_result is not None and prediction_result is not None:\n",
    "        return ground_truth_result == prediction_result\n",
    "    return False\n",
    "\n",
    "\n",
    "def compare_sqls_wrapper(example, prediction):\n",
    "  \"\"\"Wrapper for compare_sqls to access example data and establish db_connection.\"\"\"\n",
    "  db_connection = sqlite3.connect('employees.db')  # Establish connection inside the wrapper\n",
    "  ground_truth = example['gold_query']  # Access ground truth from the example\n",
    "  # Assuming prediction.sql contains the predicted SQL query\n",
    "  return compare_sqls(ground_truth, prediction.sql, db_connection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeb3b2a6-1e1a-41ea-b801-0c19c103c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class Text2SQLSignature(dspy.Signature):\n",
    "\t\"\"\"Transform a natural language query into a SQL query.\n",
    "\tYou will be given a question which will tell what you need to do\n",
    "\tand a sql_context which will give some additional context to generate the right SQL.\n",
    "\tOnly generate the SQL query nothing else. You should give one correct answer.\n",
    "\tstarting and ending with ```\n",
    "\t\"\"\"\n",
    "\n",
    "\tquestion = dspy.InputField(desc=\"Natural language query\")\n",
    "\tsql_context = dspy.InputField(desc=\"Context for the query\")\n",
    "\tsql = dspy.OutputField(desc=\"SQL Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a585fc-5bc3-4910-a81e-f848c2824846",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sql_from_query = dspy.Predict(signature=Text2SQLSignature)\n",
    "result = generate_sql_from_query(\n",
    "    question='What is the average age of employees in the Sales department?',\n",
    "    # sql_context= '\\n'.join(list(india_tb_dict))[:200]\n",
    "    sql_context = table_schemas\n",
    ")\n",
    "\n",
    "print(\"Raw result:\", result.sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fe426a1-d304-4239-850c-5dcbaf76e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2SQLProgram(dspy.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.program = dspy.ChainOfThought(signature=Text2SQLSignature)\n",
    "\n",
    "\tdef forward(self, question, sql_context):\n",
    "\t\treturn self.program(\n",
    "\t\t\tquestion=question,\n",
    "\t\t\tsql_context=sql_context\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa60bfee-2307-4eee-bff2-3ce605cce330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program = Predict(StringSignature(question, sql_context -> reasoning, sql\n",
      "    instructions='Transform a natural language query into a SQL query.\\nYou will be given a question which will tell what you need to do\\nand a sql_context which will give some additional context to generate the right SQL.\\nOnly generate the SQL query nothing else. You should give one correct answer.\\nstarting and ending with ```'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Natural language query', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    sql_context = Field(annotation=str required=True json_schema_extra={'desc': 'Context for the query', '__dspy_field_type': 'input', 'prefix': 'Sql Context:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    sql = Field(annotation=str required=True json_schema_extra={'desc': 'SQL Query', '__dspy_field_type': 'output', 'prefix': 'Sql:'})\n",
      "))\n",
      "\n",
      "REASONING:\n",
      "\n",
      "To determine the number of employees who are not currently active, we need to filter the 'employee_data' table for rows where the 'EmployeeStatus' column indicates inactivity. This could be represented by a specific value such as 'Inactive' or 'Terminated'. We then count the number of such rows.\n",
      "\n",
      "SQL:\n",
      "\n",
      "SELECT COUNT(*) AS InactiveEmployeeCount FROM employee_data WHERE EmployeeStatus = 'Inactive';\n",
      "SELECT COUNT(*) AS InactiveEmployeeCount FROM employee_data WHERE EmployeeStatus = 'Inactive';\n"
     ]
    }
   ],
   "source": [
    "text2sql = Text2SQLProgram()\n",
    "\n",
    "print(text2sql)\n",
    "\n",
    "result = text2sql(question='How many employees are currently not active?', sql_context=table_schemas)\n",
    "\n",
    "for k, v in result.items():\n",
    "    print(f\"\\n{k.upper()}:\\n\")\n",
    "    print(v)\n",
    "\n",
    "print(result.sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5527f59c-cd74-486f-8687-16dbaf2c50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 97.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ground truth sql query:  SELECT COUNT(*)FROM employee_engagement_survey_data WHERE SatisfactionScore > 8;\n",
      "ground truth result:  [(0,)]\n",
      "prediction sql query:  SELECT COUNT(*)AS NumberOfEmployees FROM employee_engagement_survey_data WHERE SatisfactionScore > 8;\n",
      "prediction result:  [(0,)]\n",
      "\n",
      "ground truth sql query:  SELECT Title FROM recruitment_data WHERE State='CA';\n",
      "ground truth result:  [('Public relations officer',)]\n",
      "prediction sql query:  SELECT DISTINCT Title FROM recruitment_data WHERE State = 'California';\n",
      "prediction result:  []\n",
      "\n",
      "ground truth sql query:  SELECT ADEmail FROM employee_data WHERE EmpID=200;\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT ADEmail FROM employee_data WHERE EmpID = 200;\n",
      "prediction result:  []\n",
      "\n",
      "ground truth sql query:  SELECT Trainer FROM training_and_development_data WHERE TrainingType='External';\n",
      "ground truth result:  [('Yolanda Wilson',), ('Lori Mckee',), ('Hannah Smith',), ('Christine Stevens',), ('Bonnie King',), ('Jennifer Cline MD',), ('Joseph Gray',), ('Dale Heath',), ('Kelly Mays',), ('Jennifer Miller',), ('Anthony Young',), ('Tanya Lozano',), ('Christopher Mueller',), ('Kristi Hampton',), ('Donna Joseph',), ('Kevin Turner',), ('Jonathan Anderson',), ('Robert Kennedy',), ('Drew Delacruz',), ('Teresa Long',), ('Brandy Young',), ('Dustin Lewis',), ('Sharon Mcconnell',), ('Robin Christensen',), ('Manuel Byrd',), ('Julia Hernandez',), ('Micheal Munoz',), ('Frank Harris',), ('Christian Higgins',), ('Tiffany Thornton',), ('Wyatt Gray',), ('Lisa Mitchell',), ('Amy Gomez',), ('Michael Garcia',), ('David Brown',)]\n",
      "prediction sql query:  SELECT DISTINCT Trainer FROM training_and_development_data WHERE TrainingType = 'External';\n",
      "prediction result:  [('Yolanda Wilson',), ('Lori Mckee',), ('Hannah Smith',), ('Christine Stevens',), ('Bonnie King',), ('Jennifer Cline MD',), ('Joseph Gray',), ('Dale Heath',), ('Kelly Mays',), ('Jennifer Miller',), ('Anthony Young',), ('Tanya Lozano',), ('Christopher Mueller',), ('Kristi Hampton',), ('Donna Joseph',), ('Kevin Turner',), ('Jonathan Anderson',), ('Robert Kennedy',), ('Drew Delacruz',), ('Teresa Long',), ('Brandy Young',), ('Dustin Lewis',), ('Sharon Mcconnell',), ('Robin Christensen',), ('Manuel Byrd',), ('Julia Hernandez',), ('Micheal Munoz',), ('Frank Harris',), ('Christian Higgins',), ('Tiffany Thornton',), ('Wyatt Gray',), ('Lisa Mitchell',), ('Amy Gomez',), ('Michael Garcia',), ('David Brown',)]\n",
      "\n",
      "ground truth sql query:  SELECT strftime('%Y', '20' || substr(TrainingDate, 8, 2)|| '-' || CASE substr(TrainingDate, 4, 3)WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(TrainingDate, 1, 2))AS TrainingYear, MAX(TrainingCost)- MIN(TrainingCost)AS CostDifference FROM training_and_development_data GROUP BY strftime('%Y', '20' || substr(TrainingDate, 8, 2)|| '-' || CASE substr(TrainingDate, 4, 3)WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(TrainingDate, 1, 2));\n",
      "ground truth result:  [('2022', 839.37), ('2023', 866.77)]\n",
      "prediction sql query:  SELECT strftime('%Y', TrainingDate)AS Year, MAX(TrainingCost)- MIN(TrainingCost)AS CostDifference FROM training_and_development_data GROUP BY Year;\n",
      "prediction result:  [(None, 882.66)]\n",
      "\n",
      "ground truth sql query:  SELECT FirstName, LastName FROM employee_data e WHERE EmpID IN(SELECT EmpID FROM training_and_development_data GROUP BY EmpID, Location HAVING COUNT(*)> 2);\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT DISTINCT e.FirstName, e.LastName FROM employee_data e JOIN(SELECT EmpID, Location FROM training_and_development_data GROUP BY EmpID, Location HAVING COUNT(*)> 2)tdd ON e.EmpID = tdd.EmpID;\n",
      "prediction result:  []\n",
      "\n",
      "ground truth sql query:  SELECT FirstName, LastName, DepartmentType, EngagementScore FROM employee_engagement_survey_data ees JOIN employee_data ed ON ees.EmpID = ed.EmpID WHERE EngagementScore =(SELECT MIN(EngagementScore)FROM employee_engagement_survey_data WHERE DepartmentType = ed.DepartmentType);\n",
      "ground truth result:  [('Dorian', 'Wu', 'IT/IS', 1)]\n",
      "prediction sql query:  WITH DepartmentMinEngagement AS(SELECT e.DepartmentType, MIN(s.EngagementScore)AS MinEngagementScore FROM employee_data e JOIN employee_engagement_survey_data s ON e.EmpID = s.EmpID GROUP BY e.DepartmentType)SELECT e.EmpID, e.FirstName, e.LastName, e.DepartmentType, s.EngagementScore FROM employee_data e JOIN employee_engagement_survey_data s ON e.EmpID = s.EmpID JOIN DepartmentMinEngagement d ON e.DepartmentType = d.DepartmentType AND s.EngagementScore = d.MinEngagementScore;\n",
      "prediction result:  [(2243, 'Dorian', 'Wu', 'IT/IS', 1), (2848, 'Pierre', 'Tate', 'Production', 2)]\n",
      "\n",
      "Execution Accuracy: 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db_connection = sqlite3.connect('employees.db')\n",
    "\n",
    "scores = []\n",
    "\n",
    "for x in tqdm(testset, total=len(testset)):\n",
    "    # Assuming text2sql function is available and works correctly\n",
    "    prediction = text2sql(question=x['question'], sql_context=table_schemas)\n",
    "    ground_truth = x['gold_query']\n",
    "\n",
    "    # Compare SQL execution results\n",
    "    score = compare_sqls(ground_truth=ground_truth, prediction=prediction.sql, db_connection=db_connection)\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "# Print the final score\n",
    "print(f\"\\nExecution Accuracy: {sum(scores)}/{len(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "041629d4-b13c-43e5-85f0-e83229b10373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n",
      "ground truth sql query:  SELECT TrainingProgramName FROM training_and_development_data WHERE TrainingDurationInDays > 5;\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT DISTINCT TrainingProgramName FROM training_and_development_data WHERE TrainingDurationInDays > 5;\n",
      "prediction result:  []\n",
      "Error executing SQL query: no such function: FLOOR\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                         | 0/5 [00:00<?, ?it/s]\n",
      "ground truth sql query:  SELECT FLOOR((julianday(DATE('now'))- julianday(CASE WHEN LENGTH(StartDate)= 9 THEN '20' || substr(StartDate, 8, 2)|| '-' || CASE substr(StartDate, 4, 3)WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2)ELSE StartDate END))/ 365 / 5)* 5 AS TenureGroup, AVG(SatisfactionScore)AS AvgSatisfaction FROM employee_data ed JOIN employee_engagement_survey_data ees ON ed.EmpID = ees.EmpID WHERE StartDate IS NOT NULL AND SatisfactionScore IS NOT NULL GROUP BY TenureGroup ORDER BY TenureGroup;\n",
      "ground truth result:  None\n",
      "prediction sql query:  WITH TenureData AS(SELECT e.EmpID,(strftime('%Y', 'now')- strftime('%Y', e.StartDate))AS TenureYears, s.SatisfactionScore FROM employee_data e JOIN employee_engagement_survey_data s ON e.EmpID = s.EmpID), TenureGroups AS(SELECT EmpID, SatisfactionScore,(TenureYears / 5)* 5 AS TenureGroup FROM TenureData)SELECT TenureGroup, AVG(SatisfactionScore)AS AverageSatisfactionScore FROM TenureGroups GROUP BY TenureGroup ORDER BY TenureGroup;\n",
      "prediction result:  [(None, 2.5)]\n",
      "Average Metric: 1.00 / 2 (50.0%):  20%|██████████                                        | 1/5 [00:00<00:00, 27.75it/s]\n",
      "ground truth sql query:  SELECT COUNT(*)FROM recruitment_data WHERE ApplicationDate='15-Jan-24';\n",
      "ground truth result:  [(0,)]\n",
      "prediction sql query:  SELECT COUNT(*)AS ApplicantCount FROM recruitment_data WHERE ApplicationDate = '2024-01-15';\n",
      "prediction result:  [(0,)]\n",
      "Average Metric: 2.00 / 3 (66.7%):  40%|████████████████████                              | 2/5 [00:00<00:00, 38.43it/s]\n",
      "ground truth sql query:  SELECT SUM(TrainingCost)FROM training_and_development_data WHERE TrainingDate LIKE '%23';\n",
      "ground truth result:  [(23383.02,)]\n",
      "prediction sql query:  SELECT SUM(TrainingCost)AS TotalTrainingCost FROM training_and_development_data WHERE strftime('%Y', TrainingDate)= '2023';\n",
      "prediction result:  [(None,)]\n",
      "Average Metric: 2.00 / 4 (50.0%):  60%|██████████████████████████████                    | 3/5 [00:00<00:00, 57.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:22:33 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'What is the engagement score of employee with ID 101?', 'gold_query': 'SELECT EngagementScore FROM employee_engagement_survey_data WHERE EmpID=101;'}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77904 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77904 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 4 (50.0%): 100%|██████████████████████████████████████████████████| 5/5 [01:02<00:00, 12.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:22:33 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 5 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40.0\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import LabeledFewShot\n",
    "from dspy import Evaluate\n",
    "\n",
    "trainset = [dspy.Example(sql_context = table_schemas, **d).with_inputs('question', 'sql_context') for d in trainset]\n",
    "devset = [dspy.Example(sql_context = table_schemas, **d).with_inputs('question', 'sql_context') for d in devset]\n",
    "\n",
    "text2sql = Text2SQLProgram()\n",
    "\n",
    "def compare_sqls_wrapper_with_trace(example, prediction, trace=None):  # Add trace argument\n",
    "    \"\"\"Wrapper for compare_sqls to access example data and establish db_connection.\"\"\"\n",
    "    db_connection = sqlite3.connect('employees.db')  # Establish connection inside the wrapper\n",
    "    ground_truth = example['gold_query']  # Access ground truth from the example\n",
    "    # Assuming prediction.sql contains the predicted SQL query\n",
    "    return compare_sqls(ground_truth, prediction.sql, db_connection)\n",
    "\n",
    "# k = number of few shot examples\n",
    "optimizer = LabeledFewShot(k=4)\n",
    "\n",
    "optimized_text2sql = optimizer.compile(\n",
    "    student=text2sql,\n",
    "    trainset=trainset,\n",
    ")\n",
    "\n",
    "evaluate = Evaluate(\n",
    "    devset=devset,\n",
    "    metric=compare_sqls_wrapper_with_trace,\n",
    "    num_threads=3,\n",
    "    display_progress=True,\n",
    "    display_table=0\n",
    ")\n",
    "\n",
    "# Get the evaluation results\n",
    "results = evaluate(optimized_text2sql)\n",
    "\n",
    "# Access the individual scores (assuming they are stored in a 'scores' attribute)\n",
    "scores = results\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8dffbd4-1e0c-4147-9971-14f72a776100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to bootstrap 10 candidate sets.\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\n",
      "ground truth sql query:  SELECT COUNT(*)FROM employee_data WHERE EmployeeStatus='Active';\n",
      "ground truth result:  [(51,)]\n",
      "prediction sql query:  SELECT COUNT(*)AS ActiveEmployeeCount FROM employee_data WHERE EmployeeStatus = 'Active';\n",
      "prediction result:  [(51,)]\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|                                                        | 0/20 [00:00<?, ?it/s]\n",
      "ground truth sql query:  SELECT DISTINCT e.FirstName, e.LastName FROM employee_data e JOIN training_and_development_data t1 ON e.EmpID = t1.EmpID WHERE t1.TrainingType = 'Internal';\n",
      "ground truth result:  [('Ellie', 'Holder')]\n",
      "prediction sql query:  SELECT e.EmpID, e.FirstName, e.LastName FROM employee_data e JOIN training_and_development_data t ON e.EmpID = t.EmpID WHERE t.TrainingOutcome = 'Completed';\n",
      "prediction result:  []\n",
      "\n",
      "ground truth sql query:  SELECT FirstName, LastName FROM employee_data WHERE DepartmentType =(SELECT DepartmentType FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe')OR Title =(SELECT Title FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe');\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT DISTINCT e.FirstName, e.LastName FROM employee_data e WHERE e.DepartmentType =(SELECT DepartmentType FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe')OR e.Title =(SELECT Title FROM employee_data WHERE FirstName = 'Jane' AND LastName = 'Doe');\n",
      "prediction result:  []\n",
      "Average Metric: 2.00 / 3 (66.7%):  10%|████▉                                            | 2/20 [00:00<00:00, 36.37it/s]\n",
      "ground truth sql query:  SELECT DesiredSalary FROM recruitment_data WHERE Title='Software Engineer';\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT DesiredSalary FROM recruitment_data WHERE Title = 'Software Engineer';\n",
      "prediction result:  []\n",
      "Average Metric: 3.00 / 4 (75.0%):  15%|███████▎                                         | 3/20 [00:00<00:00, 54.55it/s]\n",
      "ground truth sql query:  SELECT FirstName, LastName FROM employee_data WHERE BusinessUnit='Sales';\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT FirstName, LastName FROM employee_data WHERE DepartmentType = 'Sales';\n",
      "prediction result:  [('Michelle', 'Carter'), ('Alfred', 'Digitale'), ('Fernando', 'Richard'), ('Davian', 'Davis'), ('Gabriel', 'Swanson')]\n",
      "Average Metric: 3.00 / 5 (60.0%):  20%|█████████▊                                       | 4/20 [00:00<00:00, 51.92it/s]\n",
      "ground truth sql query:  SELECT COUNT(*)FROM training_and_development_data WHERE Location='Brandonview';\n",
      "ground truth result:  [(0,)]\n",
      "prediction sql query:  SELECT COUNT(DISTINCT TrainingProgramName)AS NumberOfPrograms FROM training_and_development_data WHERE Location = 'Brandonview';\n",
      "prediction result:  [(0,)]\n",
      "Average Metric: 4.00 / 6 (66.7%):  30%|██████████████▋                                  | 6/20 [00:19<00:00, 54.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:28:04 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'What is the training outcome of the employee with ID 150?', 'gold_query': 'SELECT TrainingOutcome FROM training_and_development_data WHERE EmpID=150;'}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.', 'details': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 6 (66.7%):  35%|█████████████████▏                               | 7/20 [02:04<05:11, 23.93s/it]\n",
      "ground truth sql query:  SELECT WorkLifeBalanceScore FROM employee_engagement_survey_data WHERE SurveyDate='10/10/2024';\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT WorklifeBalanceScore FROM employee_engagement_survey_data WHERE SurveyDate = '2024-05-10';\n",
      "prediction result:  []\n",
      "Average Metric: 5.00 / 7 (71.4%):  35%|█████████████████▏                               | 7/20 [02:04<05:11, 23.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:29:02 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'What are the names of all male applicants?', 'gold_query': \"SELECT FirstName, LastName FROM recruitment_data WHERE Gender='Male';\"}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77516 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77516 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  45%|██████████████████████                           | 9/20 [03:02<04:42, 25.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:29:03 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'What are the survey details for employees with engagement scores below 5?', 'gold_query': 'SELECT * FROM employee_engagement_survey_data WHERE EngagementScore < 5;'}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77514 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77514 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  50%|████████████████████████                        | 10/20 [03:03<03:27, 20.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:29:04 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'Who are the employees whose last training program was more than a year ago?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE EmpID IN (SELECT EmpID FROM training_and_development_data GROUP BY EmpID HAVING MAX(TrainingDate < date('now', '-2 year')));\"}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.', 'details': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 7 (71.4%):  50%|████████████████████████                        | 10/20 [03:04<03:27, 20.80s/it]\n",
      "ground truth sql query:  SELECT Title FROM employee_data WHERE Supervisor='Jane Doe';\n",
      "ground truth result:  []\n",
      "prediction sql query:  SELECT Title FROM employee_data WHERE Supervisor = 'Jane Doe';\n",
      "prediction result:  []\n",
      "Average Metric: 6.00 / 8 (75.0%):  60%|████████████████████████████▊                   | 12/20 [03:19<02:46, 20.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:31:05 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'What is the number of hires in each year?', 'gold_query': \"SELECT strftime('%Y', '20' || substr(StartDate, 8, 2) || '-' || CASE substr(StartDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2)) AS HireYear, COUNT(*) AS EmployeeCount FROM employee_data WHERE EmployeeStatus = 'Active' AND StartDate IS NOT NULL AND StartDate != '' GROUP BY strftime('%Y', '20' || substr(StartDate, 8, 2) || '-' || CASE substr(StartDate, 4, 3) WHEN 'Jan' THEN '01' WHEN 'Feb' THEN '02' WHEN 'Mar' THEN '03' WHEN 'Apr' THEN '04' WHEN 'May' THEN '05' WHEN 'Jun' THEN '06' WHEN 'Jul' THEN '07' WHEN 'Aug' THEN '08' WHEN 'Sep' THEN '09' WHEN 'Oct' THEN '10' WHEN 'Nov' THEN '11' WHEN 'Dec' THEN '12' END || '-' || substr(StartDate, 1, 2));\"}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.', 'details': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 8 (75.0%):  65%|███████████████████████████████▏                | 13/20 [05:05<03:30, 30.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:32:04 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'Who are the names of employees who attended all training programs conducted in 2023?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE NOT EXISTS (SELECT 1 FROM training_and_development_data t1 WHERE TrainingDate LIKE '%23' AND t1.TrainingType NOT IN (SELECT TrainingType FROM training_and_development_data t2 WHERE t2.EmpID = employee_data.EmpID));\"}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77333 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77333 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 8 (75.0%):  70%|█████████████████████████████████▌              | 14/20 [06:05<03:31, 35.31s/it]\n",
      "ground truth sql query:  SELECT TrainingType, AVG(TrainingCost)AS AvgCost, COUNT(*)AS ProgramCount FROM training_and_development_data GROUP BY TrainingType;\n",
      "ground truth result:  [('External', 576.7305714285715, 35), ('Internal', 477.5716129032258, 31)]\n",
      "prediction sql query:  SELECT TrainingType, AVG(TrainingCost)AS AverageCost, COUNT(*)AS TotalPrograms FROM training_and_development_data GROUP BY TrainingType;\n",
      "prediction result:  [('External', 576.7305714285715, 35), ('Internal', 477.5716129032258, 31)]\n",
      "Average Metric: 7.00 / 9 (77.8%):  70%|█████████████████████████████████▌              | 14/20 [06:05<03:31, 35.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:32:05 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'Who are the employees who have completed a training program lasting more than 3 days and with a cost above $500?', 'gold_query': 'SELECT e.FirstName, e.LastName, t.TrainingProgramName FROM employee_data e JOIN training_and_development_data t ON e.EmpID = t.EmpID WHERE t.TrainingDurationInDays > 3 AND t.TrainingCost > 500;'}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.', 'details': 'Rate limit of 10 per 60s exceeded for UserByModelByMinute. Please wait 57 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 9 (77.8%):  80%|██████████████████████████████████████▍         | 16/20 [06:05<01:33, 23.39s/it]\n",
      "ground truth sql query:  SELECT AVG(EngagementScore)FROM employee_engagement_survey_data;\n",
      "ground truth result:  [(2.9295774647887325,)]\n",
      "prediction sql query:  SELECT AVG(EngagementScore)AS AverageEngagementScore FROM employee_engagement_survey_data;\n",
      "prediction result:  [(2.9295774647887325,)]\n",
      "Average Metric: 8.00 / 10 (80.0%):  85%|███████████████████████████████████████▉       | 17/20 [06:19<01:10, 23.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:33:05 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'Who are the employees who have not attended any training program in the last two years?', 'gold_query': \"SELECT FirstName, LastName FROM employee_data WHERE EmpID NOT IN (SELECT EmpID FROM training_and_development_data WHERE TrainingDate > date('now', '-2 years'));\"}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77273 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77273 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 10 (80.0%):  90%|██████████████████████████████████████████▎    | 18/20 [07:05<00:51, 25.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/28 13:34:05 ERROR dspy.utils.parallelizer: Error processing item Example({'sql_context': '\\n-- Employee Data Table\\nCREATE TABLE employee_data (\\n    EmpID INTEGER,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    StartDate TEXT,\\n    ExitDate TEXT,\\n    Title TEXT,\\n    Supervisor TEXT,\\n    ADEmail TEXT,\\n    BusinessUnit TEXT,\\n    EmployeeStatus TEXT,\\n    EmployeeType TEXT,\\n    PayZone TEXT,\\n    EmployeeClassificationType TEXT,\\n    TerminationType TEXT,\\n    TerminationDescription TEXT,\\n    DepartmentType TEXT,\\n    Division TEXT,\\n    DOB TEXT,\\n    State TEXT,\\n    JobFunctionDescription TEXT,\\n    GenderCode TEXT,\\n    LocationCode INTEGER,\\n    RaceDesc TEXT,\\n    MaritalDesc TEXT,\\n    PerformanceScore TEXT,\\n    CurrentEmployeeRating INTEGER\\n);\\n\\n-- Recruitment Data Table\\nCREATE TABLE recruitment_data (\\n    ApplicantID INTEGER,\\n    ApplicationDate TEXT,\\n    FirstName TEXT,\\n    LastName TEXT,\\n    Gender TEXT,\\n    DOB TEXT,\\n    PhoneNumber TEXT,\\n    Email TEXT,\\n    Address TEXT,\\n    City TEXT,\\n    State TEXT,\\n    ZipCode INTEGER,\\n    Country TEXT,\\n    EducationLevel TEXT,\\n    YearsofExperience INTEGER,\\n    DesiredSalary REAL,\\n    Title TEXT,\\n    Status TEXT\\n);\\n\\n-- Training and Development Data Table\\nCREATE TABLE training_and_development_data (\\n    EmpID INTEGER,\\n    TrainingDate TEXT,\\n    TrainingProgramName TEXT,\\n    TrainingType TEXT,\\n    TrainingOutcome TEXT,\\n    Location TEXT,\\n    Trainer TEXT,\\n    TrainingDurationInDays INTEGER,\\n    TrainingCost INTEGER\\n);\\n\\n-- Employee Engagement Survey Data Table\\nCREATE TABLE employee_engagement_survey_data (\\n    EmpID INTEGER,\\n    SurveyDate TEXT,\\n    EngagementScore INTEGER,\\n    SatisfactionScore INTEGER,\\n    WorklifeBalanceScore INTEGER\\n);\\n', 'question': 'List all terminated employees along with their termination reasons.', 'gold_query': 'SELECT FirstName, LastName, TerminationDescription FROM employee_data WHERE TerminationType IS NOT NULL;'}) (input_keys={'sql_context', 'question'}): litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77212 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77212 seconds before retrying.'}}. Set `provide_traceback=True` to see the stack trace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 10 (80.0%):  95%|████████████████████████████████████████████▋  | 19/20 [08:05<00:32, 32.10s/it]"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77210 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77210 seconds before retrying.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\llms\\OpenAI\\openai.py:860\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 860\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\llms\\OpenAI\\openai.py:796\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[0;32m    784\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mpre_call(\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    786\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mopenai_client\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m     },\n\u001b[0;32m    793\u001b[0m )\n\u001b[0;32m    795\u001b[0m headers, response \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 796\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_sync_openai_chat_completion_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m )\n\u001b[0;32m    803\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mmodel_call_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m headers\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\llms\\OpenAI\\openai.py:657\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[1;34m(self, openai_client, data, timeout)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\llms\\OpenAI\\openai.py:639\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[1;34m(self, openai_client, data, timeout)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 639\u001b[0m     raw_response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_raw_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_legacy_response.py:356\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[1;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    828\u001b[0m validate_response_format(response_format)\n\u001b[1;32m--> 829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1277\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m )\n\u001b[1;32m-> 1280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1095\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1093\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77272 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77272 seconds before retrying.'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\main.py:1607\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[0;32m   1601\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[0;32m   1602\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   1603\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m   1604\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m   1605\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[0;32m   1606\u001b[0m     )\n\u001b[1;32m-> 1607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1610\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\main.py:1580\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1580\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_chat_completions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1588\u001b[0m \u001b[43m            \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1589\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1590\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1591\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1592\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   1594\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1595\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[0;32m   1596\u001b[0m \u001b[43m            \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1599\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\llms\\OpenAI\\openai.py:870\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    871\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code, message\u001b[38;5;241m=\u001b[39merror_text, headers\u001b[38;5;241m=\u001b[39merror_headers\n\u001b[0;32m    872\u001b[0m )\n",
      "\u001b[1;31mOpenAIError\u001b[0m: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77272 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77272 seconds before retrying.'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\utils.py:849\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\main.py:3065\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[0;32m   3063\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3064\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[1;32m-> 3065\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3068\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2137\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[1;32m-> 2137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   2138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:378\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[0;32m    379\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRateLimitError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    380\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    381\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m    382\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    383\u001b[0m         litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original_exception\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77272 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77272 seconds before retrying.'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(max_bootstrapped_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, max_labeled_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_candidate_programs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     18\u001b[0m teleprompter \u001b[38;5;241m=\u001b[39m BootstrapFewShotWithRandomSearch(metric\u001b[38;5;241m=\u001b[39mcompare_sqls_wrapper_with_trace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m---> 20\u001b[0m optimized_program \u001b[38;5;241m=\u001b[39m \u001b[43mteleprompter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext2sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\teleprompt\\random_search.py:119\u001b[0m, in \u001b[0;36mBootstrapFewShotWithRandomSearch.compile\u001b[1;34m(self, student, teacher, trainset, valset, restrict, labeled_sample)\u001b[0m\n\u001b[0;32m    108\u001b[0m     program \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mcompile(student, teacher\u001b[38;5;241m=\u001b[39mteacher, trainset\u001b[38;5;241m=\u001b[39mtrainset_copy)\n\u001b[0;32m    110\u001b[0m evaluate \u001b[38;5;241m=\u001b[39m Evaluate(\n\u001b[0;32m    111\u001b[0m     devset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalset,\n\u001b[0;32m    112\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    116\u001b[0m     display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m )\n\u001b[1;32m--> 119\u001b[0m score, subscores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_all_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m all_subscores\u001b[38;5;241m.\u001b[39mappend(subscores)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m############ Assertion-aware Optimization ############\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:112\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[1;34m(self, program, metric, devset, num_threads, display_progress, display_table, return_all_scores, return_outputs)\u001b[0m\n\u001b[0;32m    108\u001b[0m         program\u001b[38;5;241m.\u001b[39m_suggest_failures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggest_failures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction, score\n\u001b[1;32m--> 112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(devset) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(results)\n\u001b[0;32m    115\u001b[0m results \u001b[38;5;241m=\u001b[39m [((dspy\u001b[38;5;241m.\u001b[39mPrediction(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailure_score) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\parallelizer.py:39\u001b[0m, in \u001b[0;36mParallelExecutor.execute\u001b[1;34m(self, function, data)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_isolated_single_thread(wrapped_function, data)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_multi_thread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\parallelizer.py:177\u001b[0m, in \u001b[0;36mParallelExecutor._execute_multi_thread\u001b[1;34m(self, function, data)\u001b[0m\n\u001b[0;32m    169\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m    170\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data),\n\u001b[0;32m    171\u001b[0m     dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    172\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_progress_bar,\n\u001b[0;32m    173\u001b[0m     file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m--> 177\u001b[0m     index, result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m job_cancelled:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\parallelizer.py:154\u001b[0m, in \u001b[0;36mParallelExecutor._execute_multi_thread.<locals>.cancellable_function\u001b[1;34m(parent_overrides, index_item)\u001b[0m\n\u001b[0;32m    151\u001b[0m thread_local_overrides\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m parent_overrides\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m index, \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     thread_local_overrides\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m original_overrides\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\parallelizer.py:54\u001b[0m, in \u001b[0;36mParallelExecutor._wrap_function.<locals>.wrapped\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_error_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_errors:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_jobs\u001b[38;5;241m.\u001b[39mset()\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovide_traceback:\n\u001b[0;32m     56\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing item \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStack trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\parallelizer.py:47\u001b[0m, in \u001b[0;36mParallelExecutor._wrap_function.<locals>.wrapped\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_lock:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\evaluate\\evaluate.py:101\u001b[0m, in \u001b[0;36mEvaluate.__call__.<locals>.process_item\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_item\u001b[39m(example):\n\u001b[1;32m--> 101\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     score \u001b[38;5;241m=\u001b[39m metric(example, prediction)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Increment assert and suggest failures to program's attributes\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\callback.py:234\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# If no callbacks are provided, just call the function\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m call_id \u001b[38;5;241m=\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\primitives\\program.py:24\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m, in \u001b[0;36mText2SQLProgram.forward\u001b[1;34m(self, question, sql_context)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, question, sql_context):\n\u001b[1;32m----> 7\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43msql_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_context\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\callback.py:234\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# If no callbacks are provided, just call the function\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m call_id \u001b[38;5;241m=\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\primitives\\program.py:24\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\predict\\chain_of_thought.py:44\u001b[0m, in \u001b[0;36mChainOfThought.forward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivated \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m     43\u001b[0m signature \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict\u001b[38;5;241m.\u001b[39mextended_signature \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivated \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature)\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\callback.py:234\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# If no callbacks are provided, just call the function\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m call_id \u001b[38;5;241m=\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\predict\\predict.py:93\u001b[0m, in \u001b[0;36mPredict.__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\predict\\predict.py:127\u001b[0m, in \u001b[0;36mPredict.forward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdspy\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lm, dspy\u001b[38;5;241m.\u001b[39mLM):\n\u001b[1;32m--> 127\u001b[0m     completions \u001b[38;5;241m=\u001b[39m \u001b[43mv2_5_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_parse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     warn_once(\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m*** In DSPy 2.5, all LM clients except `dspy.LM` are deprecated, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munderperform, and are about to be deleted. ***\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mhttps://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\predict\\predict.py:234\u001b[0m, in \u001b[0;36mv2_5_generate\u001b[1;34m(lm, lm_kwargs, signature, demos, inputs, _parse_values)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdspy\u001b[39;00m\n\u001b[0;32m    232\u001b[0m adapter \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39madapter \u001b[38;5;129;01mor\u001b[39;00m dspy\u001b[38;5;241m.\u001b[39mChatAdapter()\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43madapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_parse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_parse_values\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\adapters\\base.py:20\u001b[0m, in \u001b[0;36mAdapter.__call__\u001b[1;34m(self, lm, lm_kwargs, signature, demos, inputs, _parse_values)\u001b[0m\n\u001b[0;32m     17\u001b[0m inputs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(signature, demos, inputs)\n\u001b[0;32m     18\u001b[0m inputs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(prompt\u001b[38;5;241m=\u001b[39minputs_) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs_, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(messages\u001b[38;5;241m=\u001b[39minputs_)\n\u001b[1;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\utils\\callback.py:234\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# If no callbacks are provided, just call the function\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m call_id \u001b[38;5;241m=\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\clients\\lm.py:97\u001b[0m, in \u001b[0;36mLM.__call__\u001b[1;34m(self, prompt, messages, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     completion \u001b[38;5;241m=\u001b[39m cached_litellm_text_completion \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;28;01melse\u001b[39;00m litellm_text_completion\n\u001b[1;32m---> 97\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    102\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    103\u001b[0m         {\n\u001b[0;32m    104\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: c\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(c, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    108\u001b[0m     ]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\clients\\lm.py:295\u001b[0m, in \u001b[0;36mrequest_cache.<locals>.decorator.<locals>.wrapper\u001b[1;34m(request, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# If the cache key cannot be computed (e.g. because it contains a value that cannot\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# be converted to JSON), bypass the cache and call the target function directly\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\cachetools\\__init__.py:771\u001b[0m, in \u001b[0;36mcached.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# key not found\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;66;03m# in case of a race, prefer the item already in the cache\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\clients\\lm.py:285\u001b[0m, in \u001b[0;36mrequest_cache.<locals>.decorator.<locals>.func_cached\u001b[1;34m(key, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;129m@cached\u001b[39m(\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# NB: cachetools doesn't support maxsize=None; it recommends using float(\"inf\") instead\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     cache\u001b[38;5;241m=\u001b[39mLRUCache(maxsize\u001b[38;5;241m=\u001b[39mmaxsize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc_cached\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, request: Dict[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\clients\\lm.py:304\u001b[0m, in \u001b[0;36mcached_litellm_completion\u001b[1;34m(request, num_retries)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;129m@request_cache\u001b[39m(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_litellm_completion\u001b[39m(request: Dict[\u001b[38;5;28mstr\u001b[39m, Any], num_retries: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno-cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno-store\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\dspy\\clients\\lm.py:312\u001b[0m, in \u001b[0;36mlitellm_completion\u001b[1;34m(request, num_retries, cache)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlitellm_completion\u001b[39m(request: Dict[\u001b[38;5;28mstr\u001b[39m, Any], num_retries: \u001b[38;5;28mint\u001b[39m, cache\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno-cache\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno-store\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\utils.py:940\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, openai\u001b[38;5;241m.\u001b[39mAPIError)\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, openai\u001b[38;5;241m.\u001b[39mTimeout)\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, openai\u001b[38;5;241m.\u001b[39mAPIConnectionError)\n\u001b[0;32m    938\u001b[0m     ):\n\u001b[0;32m    939\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_retries\n\u001b[1;32m--> 940\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(e, litellm\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mContextWindowExceededError)\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m context_window_fallback_dict\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m context_window_fallback_dict\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_litellm_router_call\n\u001b[0;32m    946\u001b[0m ):\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\main.py:3098\u001b[0m, in \u001b[0;36mcompletion_with_retries\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3095\u001b[0m     retryer \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\n\u001b[0;32m   3096\u001b[0m         stop\u001b[38;5;241m=\u001b[39mtenacity\u001b[38;5;241m.\u001b[39mstop_after_attempt(num_retries), reraise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3097\u001b[0m     )\n\u001b[1;32m-> 3098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretryer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\utils.py:960\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[0;32m    957\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[0;32m    958\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[0;32m    959\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\utils.py:849\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    847\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\main.py:3065\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[0;32m   3062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m   3063\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3064\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[1;32m-> 3065\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3068\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2137\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[1;32m-> 2137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   2138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2139\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mLITELLM_EXCEPTION_TYPES:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\myenv\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:378\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original_exception\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m    377\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[0;32m    379\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRateLimitError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    380\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    381\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m    382\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    383\u001b[0m         litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[0;32m    384\u001b[0m     )\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original_exception\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n\u001b[0;32m    386\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77210 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 77210 seconds before retrying.'}}"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "from dspy import *\n",
    "\n",
    "trainset = [dspy.Example(**d).with_inputs('question', 'sql_context') for d in trainset]\n",
    "devset = [dspy.Example(**d).with_inputs('question', 'sql_context') for d in devset]\n",
    "\n",
    "text2sql = Text2SQLProgram()\n",
    "\n",
    "def compare_sqls_wrapper_with_trace(example, prediction, trace=None):  # Add trace argument\n",
    "    \"\"\"Wrapper for compare_sqls to access example data and establish db_connection.\"\"\"\n",
    "    db_connection = sqlite3.connect('employees.db')  # Establish connection inside the wrapper\n",
    "    ground_truth = example['gold_query']  # Access ground truth from the example\n",
    "    # Assuming prediction.sql contains the predicted SQL query\n",
    "    return compare_sqls(ground_truth, prediction.sql, db_connection)\n",
    "\n",
    "config = dict(max_bootstrapped_demos=4, max_labeled_demos=4, num_candidate_programs=10, num_threads=4)\n",
    "teleprompter = BootstrapFewShotWithRandomSearch(metric=compare_sqls_wrapper_with_trace, **config)\n",
    "\n",
    "optimized_program = teleprompter.compile(\n",
    "    text2sql,\n",
    "    trainset=trainset[:5],\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6aea173-1b95-4c61-aec0-b9ee35f3ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_program.save('fewshot_optimized_text2sql_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3dc2e3-317a-4169-9164-99e89921e154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55096449-49eb-45f9-9602-d724ad931729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Correctness(dspy.Signature):\n",
    "    \"\"\"Assess if the SQL query accurately answers the given natural language query based on the provided context.\"\"\"\n",
    "\n",
    "    sql_prompt = dspy.InputField(desc=\"Natural language query \")\n",
    "    sql_context = dspy.InputField(desc=\"Context for the query\")\n",
    "    sql = dspy.InputField(desc=\"SQL query\")\n",
    "    correct = dspy.OutputField(desc=\"Indicate whether the SQL query correctly answers the natural language query based on the given context\", prefix=\"Yes/No:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a86ac39a-a134-4bc2-ae92-b6f47f7399d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness_metric(example, pred, trace=None):\n",
    "    sql_prompt, sql_context, sql = example.sql_prompt, example.sql_context, pred.sql\n",
    "\n",
    "    correctness = dspy.Predict(Correctness)\n",
    "\n",
    "    with dspy.context(lm=evaluator_lm): \n",
    "        correct = correctness(\n",
    "            sql_prompt=sql_prompt,\n",
    "            sql_context=sql_context,\n",
    "            sql=sql,\n",
    "        )\n",
    "    \n",
    "    score = int(correct.correct==\"Yes\")\n",
    "\n",
    "    if trace is not None:\n",
    "        return score == 1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed21920-6c0a-43ea-b011-27093613fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactJudge(dspy.Signature):\n",
    "    \"\"\"Judge if the answer is factually correct based on the context.\"\"\"\n",
    "\n",
    "    sql_context = dspy.InputField(desc=\"Context for the prediction\")\n",
    "    question = dspy.InputField(desc=\"Question to be answered\")\n",
    "    answer = dspy.InputField(desc=\"Answer for the question\")\n",
    "    factually_correct = dspy.OutputField(desc=\"Is the answer factually correct based on the context?\", prefix=\"Factual[Yes/No]:\")\n",
    "\n",
    "judge = dspy.ChainOfThought(FactJudge)\n",
    "\n",
    "def factuality_metric(example, pred):\n",
    "    factual = judge(context=example.context, question=example.question, answer=pred.answer)\n",
    "    return int(factual==\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42271a-5a03-4f93-8526-4036a33bae0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

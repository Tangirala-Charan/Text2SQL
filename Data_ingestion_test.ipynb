{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7983964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\legion\\miniconda3\\envs\\myenv\\lib\\site-packages (2.0.36)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\legion\\miniconda3\\envs\\myenv\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\legion\\miniconda3\\envs\\myenv\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\legion\\miniconda3\\envs\\myenv\\lib\\site-packages (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7c4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib.request\n",
    "import ssl\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    ")\n",
    "import re\n",
    "from sqlalchemy import inspect\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text \n",
    "import dspy\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b00e3823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dsp.modules.cache_utils import cache_turn_on\n",
    "\n",
    "cache_turn_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515b7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "html_link = \"https://pages.stern.nyu.edu/~adamodar/New_Home_Page/datacurrent.html\"\n",
    "\n",
    "with urllib.request.urlopen(html_link) as url:\n",
    "    s = url.read()\n",
    "    # I'm guessing this would output the html source code ?\n",
    "    soup = BeautifulSoup(s,\"lxml\")\n",
    "\n",
    "html_table = soup.find_all(\"table\")\n",
    "req_table = html_table[1]\n",
    "hrefs_list = req_table.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75fdb02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_href = {\"US\":[],\"Europe\":[],\"Japan\":[],\"AUS_NZ_CANADA\":[],\"Emerging\":[],\"China\":[],\"India\":[],\"Global\":[]}\n",
    "\n",
    "for i in hrefs_list:\n",
    "    name = i.get_text().strip()\n",
    "    try:\n",
    "        href_attr = i['href']\n",
    "        # Only get the excel files\n",
    "        if href_attr.endswith('.xls'):\n",
    "            if \"US\" in name:\n",
    "                req_href[\"US\"].append(href_attr)\n",
    "            elif \"Europe\" in name:\n",
    "                req_href[\"Europe\"].append(href_attr)\n",
    "            elif \"Japan\" in name:\n",
    "                req_href[\"Japan\"].append(href_attr)\n",
    "            elif \"Aus\" in name:\n",
    "                req_href['AUS_NZ_CANADA'].append(href_attr)\n",
    "            elif \"Emerging\" in name:\n",
    "                req_href['Emerging'].append(href_attr)\n",
    "            elif \"China\" in name:\n",
    "                req_href['China'].append(href_attr)\n",
    "            elif \"India\" in name:\n",
    "                req_href['India'].append(href_attr)\n",
    "            elif \"Global\" in name: \n",
    "                req_href['Global'].append(href_attr)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "\n",
    "os.makedirs(\"DATA\",exist_ok=True)\n",
    "for country,excel_files in req_href.items():\n",
    "    country_path = os.path.join(\"DATA\",country) \n",
    "    os.makedirs(country_path,exist_ok=True)\n",
    "    for file in excel_files:\n",
    "        file_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "        full_file_name = os.path.join(country_path,f\"{file_name}.xls\")\n",
    "        resp = requests.get(file,verify=False)\n",
    "        output = open(full_file_name, 'wb')\n",
    "        output.write(resp.content)\n",
    "        output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in os.listdir(\"DATA\"):\n",
    "    dir_len = len(os.listdir(os.path.join(\"DATA\",country)))\n",
    "    country_len = len(req_href[country])\n",
    "    print(f'FOR {country} WE HAVE DIRECTORY LEN = {dir_len} and ACTUAL LEN = {country_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89544bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_excel = pd.ExcelFile(\"DATA/US/capex.xls\")\n",
    "sn = 'Variables & FAQ'\n",
    "sample_excel.parse(sn).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a5f654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date updated:</th>\n",
       "      <th>2024-01-05 00:00:00</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Created by:</td>\n",
       "      <td>Aswath Damodaran, adamodar@stern.nyu.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is this data?</td>\n",
       "      <td>Capital Expenditures, Acquisitions and R&amp;D and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US companies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home Page:</td>\n",
       "      <td>http://www.damodaran.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data website:</td>\n",
       "      <td>https://pages.stern.nyu.edu/~adamodar/New_Home...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Companies in each industry:</td>\n",
       "      <td>https://pages.stern.nyu.edu/~adamodar/pc/datas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Variable definitions:</td>\n",
       "      <td>https://pages.stern.nyu.edu/~adamodar/New_Home...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Industry Name</td>\n",
       "      <td>Number of Firms</td>\n",
       "      <td>Capital Expenditures (US $ millions)</td>\n",
       "      <td>Depreciation &amp; Amort ((US $ millions)</td>\n",
       "      <td>Cap Ex/Deprecn</td>\n",
       "      <td>Acquisitions (US $ millions)</td>\n",
       "      <td>Net R&amp;D (US $ millions)</td>\n",
       "      <td>Net Cap Ex/Sales</td>\n",
       "      <td>Net Cap Ex/ EBIT (1-t)</td>\n",
       "      <td>Sales/ Invested Capital (LTM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Advertising</td>\n",
       "      <td>57</td>\n",
       "      <td>775.729</td>\n",
       "      <td>1887.338</td>\n",
       "      <td>0.411018</td>\n",
       "      <td>322.559</td>\n",
       "      <td>75.08</td>\n",
       "      <td>-0.016886</td>\n",
       "      <td>-0.21812</td>\n",
       "      <td>3.283403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aerospace/Defense</td>\n",
       "      <td>70</td>\n",
       "      <td>10982.128</td>\n",
       "      <td>13311.598</td>\n",
       "      <td>0.825004</td>\n",
       "      <td>10344.75</td>\n",
       "      <td>830.4634</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.318077</td>\n",
       "      <td>1.98434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Air Transport</td>\n",
       "      <td>25</td>\n",
       "      <td>25559.725</td>\n",
       "      <td>10609.948</td>\n",
       "      <td>2.409034</td>\n",
       "      <td>368.21</td>\n",
       "      <td>73.5486</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>1.355173</td>\n",
       "      <td>1.77732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date updated:  \\\n",
       "0                  Created by:   \n",
       "1           What is this data?   \n",
       "2                   Home Page:   \n",
       "3                Data website:   \n",
       "4  Companies in each industry:   \n",
       "5        Variable definitions:   \n",
       "6                Industry Name   \n",
       "7                  Advertising   \n",
       "8            Aerospace/Defense   \n",
       "9                Air Transport   \n",
       "\n",
       "                                 2024-01-05 00:00:00  \\\n",
       "0           Aswath Damodaran, adamodar@stern.nyu.edu   \n",
       "1  Capital Expenditures, Acquisitions and R&D and...   \n",
       "2                           http://www.damodaran.com   \n",
       "3  https://pages.stern.nyu.edu/~adamodar/New_Home...   \n",
       "4  https://pages.stern.nyu.edu/~adamodar/pc/datas...   \n",
       "5  https://pages.stern.nyu.edu/~adamodar/New_Home...   \n",
       "6                                    Number of Firms   \n",
       "7                                                 57   \n",
       "8                                                 70   \n",
       "9                                                 25   \n",
       "\n",
       "                             Unnamed: 2  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "5                                   NaN   \n",
       "6  Capital Expenditures (US $ millions)   \n",
       "7                               775.729   \n",
       "8                             10982.128   \n",
       "9                             25559.725   \n",
       "\n",
       "                              Unnamed: 3      Unnamed: 4  \\\n",
       "0                                    NaN             NaN   \n",
       "1                                    NaN             NaN   \n",
       "2                                    NaN             NaN   \n",
       "3                                    NaN             NaN   \n",
       "4                                    NaN             NaN   \n",
       "5                                    NaN             NaN   \n",
       "6  Depreciation & Amort ((US $ millions)  Cap Ex/Deprecn   \n",
       "7                               1887.338        0.411018   \n",
       "8                              13311.598        0.825004   \n",
       "9                              10609.948        2.409034   \n",
       "\n",
       "                     Unnamed: 5               Unnamed: 6        Unnamed: 7  \\\n",
       "0                           NaN                      NaN               NaN   \n",
       "1                  US companies                      NaN               NaN   \n",
       "2                           NaN                      NaN               NaN   \n",
       "3                           NaN                      NaN               NaN   \n",
       "4                           NaN                      NaN               NaN   \n",
       "5                           NaN                      NaN               NaN   \n",
       "6  Acquisitions (US $ millions)  Net R&D (US $ millions)  Net Cap Ex/Sales   \n",
       "7                       322.559                    75.08         -0.016886   \n",
       "8                      10344.75                 830.4634          0.022829   \n",
       "9                        368.21                  73.5486          0.067203   \n",
       "\n",
       "               Unnamed: 8                     Unnamed: 9  \n",
       "0                     NaN                            NaN  \n",
       "1                     NaN                            NaN  \n",
       "2                     NaN                            NaN  \n",
       "3                     NaN                            NaN  \n",
       "4                     NaN                            NaN  \n",
       "5                     NaN                            NaN  \n",
       "6  Net Cap Ex/ EBIT (1-t)  Sales/ Invested Capital (LTM)  \n",
       "7                -0.21812                       3.283403  \n",
       "8                0.318077                        1.98434  \n",
       "9                1.355173                        1.77732  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_excel.parse(sample_excel.sheet_names[1]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7cec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUS_NZ_CANADA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emerging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 22.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "dir = \"DATA\"\n",
    "processed_dir = \"Processed Data\"\n",
    "all_infos_dict = []\n",
    "os.makedirs(processed_dir,exist_ok=True)\n",
    "for country in os.listdir(dir):\n",
    "    print(country)\n",
    "    file_name = os.path.join(dir,country)\n",
    "    os.makedirs(os.path.join(processed_dir,country),exist_ok=True)\n",
    "    os.makedirs(file_name,exist_ok=True)\n",
    "    for excel_file in tqdm(os.listdir(file_name)):\n",
    "        full_file_name = os.path.join(file_name,excel_file)\n",
    "        xls = pd.ExcelFile(full_file_name)\n",
    "        sns = xls.sheet_names\n",
    "        info_dict = {}\n",
    "        for sheet_name in sns:\n",
    "            if \"Var\" in sheet_name or \"var\" in sheet_name:\n",
    "                info_df = xls.parse(sheet_name)\n",
    "                info_df.dropna(how=\"all\",inplace=True)\n",
    "                info_dict = {}\n",
    "                for cols in info_df.columns:\n",
    "                    if \"End\" not in cols and 'Unnamed' not in cols:\n",
    "                        info_dict['Summary'] = cols\n",
    "                info_dict['Vars'] = info_df.values[1:].tolist()\n",
    "                all_infos_dict.append(info_dict)\n",
    "            elif \"Industry\" in sheet_name or \"industry\" in sheet_name:\n",
    "                data_df = xls.parse(sheet_name)\n",
    "        try:\n",
    "            data_df.dropna(axis=1,thresh=5,inplace=True)\n",
    "            data_df.dropna(inplace=True)\n",
    "            new_header = data_df.iloc[0] #grab the first row for the header\n",
    "        except:\n",
    "            print(full_file_name)\n",
    "            print(data_df)\n",
    "\n",
    "        data_df = data_df[1:] #take the data less the header row\n",
    "        data_df.reset_index(inplace=True,drop=True)\n",
    "        new_header = [sanitize_column_name(str(col)) for col in new_header]\n",
    "        data_df.columns = new_header #set the header row as the df header\n",
    "        save_name = full_file_name.split(\".\")[0].split(\"\\\\\")\n",
    "        save_name = save_name[-1]\n",
    "        save_file_path = os.path.join(os.path.join(processed_dir,country),save_name)\n",
    "        data_df.to_csv(save_file_path+\".csv\",index=False)\n",
    "        with open(save_file_path+\".json\", \"w\") as outfile: \n",
    "            json.dump(info_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18617e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Summary': 'To measure how much companies are reinvesting back into their long term assets, as a prelude to forecasting expected growth.',\n",
       " 'Vars': [['Capital Expenditures',\n",
       "   'Sum of the capital expenditures reported on statement of cash flows',\n",
       "   'Gross investment in long term assets, at least as defined by accountants',\n",
       "   '$ millions'],\n",
       "  ['Depreciation',\n",
       "   'Sum of the depreciation reported on statement of cash flows',\n",
       "   'Loss in value of assets, from use, as measured by accountants.',\n",
       "   '$ millions'],\n",
       "  ['Net Cap Ex',\n",
       "   'Sum of capital expenditures on statement of cash flows minus Sum of depreciation as reported in statement of cash flows',\n",
       "   'Net investment in long term assets, at least as defined by accountants',\n",
       "   '$ millions'],\n",
       "  ['Net R&D',\n",
       "   'Sum of R&D reported as expense in most recent year minus amortization of R&D, assuming capitalization',\n",
       "   'Net investment in long term assets, expanded to incorporate assets created by R&D',\n",
       "   '$ millions'],\n",
       "  ['Acquisitions',\n",
       "   'Sum of acquisitions reported on statement of cash flows (and thus does not include non-cash acquisitions, paid for with stock',\n",
       "   'Augments investment to include acquisition.',\n",
       "   '$ millions']]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_infos_dict[0]\n",
    "# save_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea08c773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry_Name</th>\n",
       "      <th>Number_of_Firms</th>\n",
       "      <th>Capital_Expenditures_US_millions_</th>\n",
       "      <th>Depreciation_Amort_US_millions_</th>\n",
       "      <th>Cap_Ex_Deprecn</th>\n",
       "      <th>Acquisitions_US_millions_</th>\n",
       "      <th>Net_R_D_US_millions_</th>\n",
       "      <th>Net_Cap_Ex_Sales</th>\n",
       "      <th>Net_Cap_Ex_EBIT_1_t_</th>\n",
       "      <th>Sales_Invested_Capital_LTM_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advertising</td>\n",
       "      <td>57</td>\n",
       "      <td>775.729</td>\n",
       "      <td>1887.338</td>\n",
       "      <td>0.411018</td>\n",
       "      <td>322.559</td>\n",
       "      <td>75.0800</td>\n",
       "      <td>-0.016886</td>\n",
       "      <td>-0.218120</td>\n",
       "      <td>3.283403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aerospace/Defense</td>\n",
       "      <td>70</td>\n",
       "      <td>10982.128</td>\n",
       "      <td>13311.598</td>\n",
       "      <td>0.825004</td>\n",
       "      <td>10344.750</td>\n",
       "      <td>830.4634</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.318077</td>\n",
       "      <td>1.984340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air Transport</td>\n",
       "      <td>25</td>\n",
       "      <td>25559.725</td>\n",
       "      <td>10609.948</td>\n",
       "      <td>2.409034</td>\n",
       "      <td>368.210</td>\n",
       "      <td>73.5486</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>1.355173</td>\n",
       "      <td>1.777320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apparel</td>\n",
       "      <td>38</td>\n",
       "      <td>1730.981</td>\n",
       "      <td>1386.480</td>\n",
       "      <td>1.248472</td>\n",
       "      <td>38.739</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.072557</td>\n",
       "      <td>1.773076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auto &amp; Truck</td>\n",
       "      <td>34</td>\n",
       "      <td>29899.486</td>\n",
       "      <td>18677.668</td>\n",
       "      <td>1.600815</td>\n",
       "      <td>193.220</td>\n",
       "      <td>983.0696</td>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.675918</td>\n",
       "      <td>1.048732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Industry_Name  Number_of_Firms  Capital_Expenditures_US_millions_  \\\n",
       "0        Advertising               57                            775.729   \n",
       "1  Aerospace/Defense               70                          10982.128   \n",
       "2      Air Transport               25                          25559.725   \n",
       "3            Apparel               38                           1730.981   \n",
       "4       Auto & Truck               34                          29899.486   \n",
       "\n",
       "   Depreciation_Amort_US_millions_  Cap_Ex_Deprecn  Acquisitions_US_millions_  \\\n",
       "0                         1887.338        0.411018                    322.559   \n",
       "1                        13311.598        0.825004                  10344.750   \n",
       "2                        10609.948        2.409034                    368.210   \n",
       "3                         1386.480        1.248472                     38.739   \n",
       "4                        18677.668        1.600815                    193.220   \n",
       "\n",
       "   Net_R_D_US_millions_  Net_Cap_Ex_Sales  Net_Cap_Ex_EBIT_1_t_  \\\n",
       "0               75.0800         -0.016886             -0.218120   \n",
       "1              830.4634          0.022829              0.318077   \n",
       "2               73.5486          0.067203              1.355173   \n",
       "3                0.9474          0.005365              0.072557   \n",
       "4              983.0696          0.026577              0.675918   \n",
       "\n",
       "   Sales_Invested_Capital_LTM_  \n",
       "0                     3.283403  \n",
       "1                     1.984340  \n",
       "2                     1.777320  \n",
       "3                     1.773076  \n",
       "4                     1.048732  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Processed Data/US/capex.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59fad866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TOKEN=\"TOKEN\"\n",
    "ENDPOINT = 'https://models.inference.ai.azure.com'\n",
    "\n",
    "os.environ['GITHUB_TOKEN']= TOKEN\n",
    "os.environ[\"OPENAI_API_KEY\"] = TOKEN\n",
    "\n",
    "os.environ['OPENAI_API_BASE'] = ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13eb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dspy.LM('openai/gpt-4o-mini', max_tokens=250)\n",
    "dspy.settings.configure(lm=model)\n",
    "\n",
    "class SQLTableMetadata(dspy.Signature):\n",
    "    \"\"\"Give a suitable table name and description about the given table\"\"\"\n",
    "    pandas_dataframe_str = dspy.InputField(desc=\"First 10 rows of a pandas dataframe delimited by newline character\")\n",
    "    table_name = dspy.OutputField(desc=\"suitable table name\")\n",
    "    table_summary = dspy.OutputField(desc=\"a summary about the table\")\n",
    "\n",
    "class CoT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prog = dspy.ChainOfThought(SQLTableMetadata)\n",
    "    \n",
    "    def forward(self, pandas_dataframe_str):\n",
    "        return self.prog(pandas_dataframe_str=pandas_dataframe_str)\n",
    "\n",
    "cot = CoT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17374875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_dir = \"Processed Data\"\n",
    "dfs_str = []\n",
    "for country in os.listdir(processed_dir):\n",
    "    country_folder = os.path.join(processed_dir,country)\n",
    "    # print(f\"{country}\")\n",
    "    for files in tqdm(os.listdir(country_folder),desc=f\"Building the summary and name for {country}\"):\n",
    "        if files.endswith(\".csv\"):\n",
    "            file_name = files.split(\".\")[0]\n",
    "            csv_file_path = os.path.join(country_folder,files)\n",
    "            df = pd.read_csv(csv_file_path,index_col=False)\n",
    "            json_file_path = os.path.join(country_folder,f\"{file_name}.json\")\n",
    "            with open(json_file_path,'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "            if 'table_name' in data and 'table_summary' in data:\n",
    "                # if data['table_name'] == \"\" or data['table_summary'] == \"\":\n",
    "                if data['table_summary'] == \"\":\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "            dfs_str.append(df.head(10).to_csv())\n",
    "            table_preds = cot(pandas_dataframe_str = df.head(10).to_csv())\n",
    "            data['table_name'] = table_preds.table_name\n",
    "            data['table_summary'] = table_preds.table_summary\n",
    "            with open(json_file_path,'w') as f:\n",
    "                json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_folder = \"Processed_Data/AUS_NZ_CANADA\"\n",
    "for files in tqdm(os.listdir(country_folder),desc=f\"Building the summary and name for {country}\"):\n",
    "    if files.endswith(\".csv\"):\n",
    "        file_name = files.split(\".\")[0]\n",
    "        csv_file_path = os.path.join(country_folder,files)\n",
    "        df = pd.read_csv(csv_file_path,index_col=False)\n",
    "        json_file_path = os.path.join(country_folder,f\"{file_name}.json\")\n",
    "        with open(json_file_path,'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "        if 'table_name' in data and 'table_summary' in data:\n",
    "            # if data['table_name'] == \"\" or data['table_summary'] == \"\":\n",
    "            if data['table_summary'] == \"\":\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "        dfs_str.append(df.head(10).to_csv())\n",
    "        table_preds = cot(pandas_dataframe_str = df.head(10).to_csv())\n",
    "        data['table_name'] = table_preds.table_name\n",
    "        data['table_summary'] = table_preds.table_summary\n",
    "        with open(json_file_path,'w') as f:\n",
    "            json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f193043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a sanitized column name\n",
    "def sanitize_column_name(col_name):\n",
    "    # Remove special characters and replace spaces with underscores\n",
    "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
    "\n",
    "\n",
    "# Function to create a table from a DataFrame using SQLAlchemy\n",
    "def create_table_from_dataframe(\n",
    "    df: pd.DataFrame, table_name: str, engine, metadata_obj\n",
    "):\n",
    "    # Sanitize column names\n",
    "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
    "    df = df.rename(columns=sanitized_columns)\n",
    "\n",
    "    # Dynamically create columns based on DataFrame columns and data types\n",
    "    columns = [\n",
    "        Column(col, String if dtype == \"object\" else Integer)\n",
    "        for col, dtype in zip(df.columns, df.dtypes)\n",
    "    ]\n",
    "\n",
    "    # Create a table with the defined columns\n",
    "    table = Table(table_name, metadata_obj, *columns)\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata_obj.create_all(engine)\n",
    "\n",
    "    # Insert data from DataFrame into the table\n",
    "    with engine.connect() as conn:\n",
    "        for _, row in df.iterrows():\n",
    "            insert_stmt = table.insert().values(**row.to_dict())\n",
    "            conn.execute(insert_stmt)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cbff7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir  = \"Processed Data\"\n",
    "def sqlalchemy_engine(region:str):\n",
    "    \"\"\"Create a SQLAlchemy engine for the given region\"\"\"\n",
    "    assert region in os.listdir(processed_dir), f\"{region} is not a valid region from {os.listdir(processed_dir)}\"\n",
    "    # Create a SQLAlchemy database for each region\n",
    "    engine = create_engine(f\"sqlite:///{region}.db\")\n",
    "    metadata_obj = MetaData()\n",
    "    region_path = os.path.join(processed_dir,region)\n",
    "    dfs = []\n",
    "    for dataframes_path in os.listdir(region_path):\n",
    "        if dataframes_path.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(region_path,dataframes_path),index_col=False)\n",
    "            dfs.append((dataframes_path,df))\n",
    "    pbar = tqdm(total=len(dfs),desc=f\"Creating tables for {region}\")\n",
    "    for _, df_table_name in enumerate(dfs):\n",
    "        table_name = df_table_name[0]\n",
    "        table_name = table_name.split(\".\")[0]\n",
    "        df = df_table_name[1]\n",
    "        # print(f\"Creating table: {table_name}\")\n",
    "        create_table_from_dataframe(df,table_name, engine, metadata_obj)\n",
    "        # print(f\"Done creating table for: {table_name}\")\n",
    "        pbar.update(1)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71af95af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating tables for India: 100%|███████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# us_engine = sqlalchemy_engine(\"US\")\n",
    "india_engine = sqlalchemy_engine(\"India\")\n",
    "# china_engine = sqlalchemy_engine(\"China\")\n",
    "# europe_engine = sqlalchemy_engine(\"Europe\")\n",
    "# global_engine = sqlalchemy_engine(\"Global\")\n",
    "# aus_nz_canada_engine = sqlalchemy_engine(\"AUS_NZ_CANADA\")\n",
    "# japan_engine = sqlalchemy_engine(\"Japan\")\n",
    "# emerging_engine = sqlalchemy_engine(\"Emerging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf581abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_infos(sql_engine:sqlalchemy.engine.base.Engine,region:str):\n",
    "    \"\"\"Get all the tables info in the database based on the given region\"\"\"\n",
    "    inspector = inspect(sql_engine)\n",
    "    table_names = inspector.get_table_names()\n",
    "    table_infos_dict = {tb: [] for tb in table_names}\n",
    "    for tb in table_names:\n",
    "        column_dict = inspector.get_columns(tb)\n",
    "        schema_str = \"\"\n",
    "        primary_keys = []\n",
    "        for col in column_dict:\n",
    "            schema_str += f\"{col['name']} ({col['type']}), \"\n",
    "            if col[\"primary_key\"] not in primary_keys:\n",
    "                primary_keys.append(col[\"name\"])\n",
    "        \n",
    "        with open(os.path.join(processed_dir,region,f\"{tb}.json\")) as f:\n",
    "            table_info = json.loads(f.read())\n",
    "        table_info = list(table_info.items())\n",
    "        # print(table_info)\n",
    "        table_infos_dict[tb] = [\n",
    "            {\n",
    "                \"table_info\": f\"Table {tb} has columns: {schema_str[:-2]}\",\n",
    "                \"table_summary\": f'{table_info[0][-1]}. {table_info[-1][-1]}. ',\n",
    "            }\n",
    "        ]\n",
    "    return table_infos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2c050-1bd3-4017-860a-e11bb4a7935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = inspect(india_engine)\n",
    "i.reflect_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb595678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Net_Income_millions_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'D_D_E_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Stock_based_Compensation_as_of_Revenue', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': '2023_0', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'CAGR_in_R_D_Last_5_years', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Average_Beta_2019_23', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Sales_Invested_Capital_LTM_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Capital_Spending_Total_Assets', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Lease_Debt_Accounting_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Cash_Firm_Value', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Std_Dev_in_Stock_Prices', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Change_in_Lease_Debt_in_millions', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Expected_Growth_in_EBIT', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Fundamental_Growth_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Impairment_as_of_Goodwill', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Expected_Growth_in_EPS_Next_5_years', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Insider_Holdings', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Lease_Debt_Accounting_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Lease_Expense_Sales', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'D_D_E_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'ROIC', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'PEG_Ratio', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Pre_tax_Operating_Margin', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'ROE_adjusted_for_R_D_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Aggregate_tax_rate_1', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Total_Levered_Beta', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'EV_EBIT_1_t__1', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Cost_of_Capital_Local_Currency_', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n",
      "{'name': 'Non_cash_WC_Sales', 'type': INTEGER(), 'nullable': True, 'default': None, 'primary_key': 0}\n"
     ]
    }
   ],
   "source": [
    "# us_tb_dict = get_table_infos(us_engine,\"US\")\n",
    "india_tb_dict = get_table_infos(india_engine,\"India\")\n",
    "# china_tb_dict = get_table_infos(china_engine,\"China\")\n",
    "# europe_tb_dict = get_table_infos(europe_engine,\"Europe\")\n",
    "# global_tb_dict = get_table_infos(global_engine,\"Global\")\n",
    "# aus_nz_canada_tb_dict = get_table_infos(aus_nz_canada_engine,\"AUS_NZ_CANADA\")\n",
    "# japan_tb_dict = get_table_infos(japan_engine,\"Japan\")\n",
    "# emerging_tb_dict = get_table_infos(emerging_engine,\"Emerging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_tb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359a48a-b3ed-48fb-b990-8ec6925ee70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
